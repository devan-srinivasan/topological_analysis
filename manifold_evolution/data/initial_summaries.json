{
    "Order of operations": "In mathematics and computer programming, the order of operations is a collection of conventions about which arithmetic operations to perform first in order to evaluate a given mathematical expression.\nThese conventions are formalized with a ranking of the operations. The rank of an operation is called its precedence, and an operation with a higher precedence is performed before operations with lower precedence. Calculators generally perform operations with the same precedence from left to right, but some programming languages and calculators adopt different conventions.\nFor example, multiplication is granted a higher precedence than addition, and it has been this way since the introduction of modern algebraic notation. Thus, in the expression 1 + 2 × 3, the multiplication is performed before addition, and the expression has the value 1 + (2 × 3) = 7, and not (1 + 2) × 3 = 9. When exponents were introduced in the 16th and 17th centuries, they were given precedence over both addition and multiplication and placed as a superscript to the right of their base. Thus 3 + 52 = 28 and 3 × 52 = 75.\nThese conventions exist to avoid notational ambiguity while allowing notation to remain brief. Where it is desired to override the precedence conventions, or even simply to emphasize them, parentheses ( ) can be used. For example, (2 + 3) × 4 = 20 forces addition to precede multiplication, while (3 + 5)2 = 64 forces addition to precede exponentiation. If multiple pairs of parentheses are required in a mathematical expression (such as in the case of nested parentheses), the parentheses may be replaced by other types of brackets to avoid confusion, as in [2 × (3 + 4)] − 5 = 9.\nThese conventions are meaningful only when the usual notation (called infix notation) is used. When functional or Polish notation are used for all operations, the order of operations results from the notation itself.",
    "Addition": "Addition, usually denoted with the plus sign +, is one of the four basic operations of arithmetic, the other three being subtraction, multiplication, and division. The addition of two whole numbers results in the total or sum of those values combined. For example, the adjacent image shows two columns of apples, one with three apples and the other with two apples, totaling to five apples. This observation is expressed as \"3 + 2 = 5\", which is read as  \"three plus two equals five\".\nBesides counting items, addition can also be defined and executed without referring to concrete objects, using abstractions called numbers instead, such as integers, real numbers, and complex numbers. Addition belongs to arithmetic, a branch of mathematics. In algebra, another area of mathematics, addition can also be performed on abstract objects such as vectors, matrices, and elements of additive groups.\nAddition has several important properties. It is commutative, meaning that the order of the numbers being added does not matter, so 3 + 2 = 2 + 3, and it is associative, meaning that when one adds more than two numbers, the order in which addition is performed does not matter. Repeated addition of 1 is the same as counting (see Successor function). Addition of 0 does not change a number. Addition also obeys rules concerning related operations such as subtraction and multiplication.\nPerforming addition is one of the simplest numerical tasks to perform. Addition of very small numbers is accessible to toddlers; the most basic task, 1 + 1, can be performed by infants as young as five months, and even some members of other animal species. In primary education, students are taught to add numbers in the decimal system, beginning with single digits and progressively tackling more difficult problems. Mechanical aids range from the ancient abacus to the modern computer, where research on the most efficient implementations of addition continues to this day.",
    "Additive inverse": "In mathematics, the additive inverse of an element x, denoted −x, is the element that when added to x, yields the additive identity. This additive identity is often the number 0 (zero), but it can also refer to a more generalized zero element.\nIn elementary mathematics, the additive inverse is often referred to as the opposite number, or the negative of a number. The unary operation of arithmetic negation is closely related to subtraction and is important in solving algebraic equations. Not all sets where addition is defined have an additive inverse, such as the natural numbers.",
    "Subtraction": "Subtraction (which is signified by the minus sign, –) is one of the four arithmetic operations along with addition, multiplication and division. Subtraction is an operation that represents removal of objects from a collection. For example, in the adjacent picture, there are 5 − 2 peaches—meaning 5 peaches with 2 taken away, resulting in a total of 3 peaches. Therefore, the difference of 5 and 2 is 3; that is, 5 − 2 = 3. While primarily associated with natural numbers in arithmetic, subtraction can also represent removing or decreasing physical and abstract quantities using different kinds of objects including negative numbers, fractions, irrational numbers, vectors, decimals, functions, and matrices.\nIn a sense, subtraction is the inverse of addition. That is, c = a − b if and only if c + b = a. In words: the difference of two numbers is the number that gives the first one when added to the second one.\nSubtraction follows several important patterns. It is anticommutative, meaning that changing the order changes the sign of the answer. It is also not associative, meaning that when one subtracts more than two numbers, the order in which subtraction is performed matters. Because 0 is the additive identity, subtraction of it does not change a number. Subtraction also obeys predictable rules concerning related operations, such as addition and multiplication. All of these rules can be proven, starting with the subtraction of integers and generalizing up through the real numbers and beyond. General binary operations that follow these patterns are studied in abstract algebra.\nIn computability theory, considering subtraction is not well-defined over natural numbers, operations between numbers are actually defined using \"truncated subtraction\" or monus.",
    "Multiplication": "Multiplication is one of the four elementary mathematical operations of arithmetic, with the other ones being addition, subtraction, and division. The result of a multiplication operation is called a product. Multiplication is often denoted by the cross symbol, ×, by the mid-line dot operator, ·, by juxtaposition, or, in programming languages, by an asterisk, *.\nThe multiplication of whole numbers may be thought of as repeated addition; that is, the multiplication of two numbers is equivalent to adding as many copies of one of them, the multiplicand, as the quantity of the other one, the multiplier; both numbers can be referred to as factors. This is to be distinguished from terms, which are added.\n\n  \n    \n      \n        a\n        ×\n        b\n        =\n        \n          \n            \n              \n                b\n                +\n                ⋯\n                +\n                b\n              \n              ⏟\n            \n          \n          \n            a\n            \n               times\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle a\\times b=\\underbrace {b+\\cdots +b} _{a{\\text{ times}}}.}\n  \n\nWhether the first factor is the multiplier or the multiplicand may be ambiguous or depend upon context. For example, the expression \n  \n    \n      \n        3\n        ×\n        4\n      \n    \n    {\\displaystyle 3\\times 4}\n  \n can be phrased as \"3 times 4\" and evaluated as \n  \n    \n      \n        4\n        +\n        4\n        +\n        4\n      \n    \n    {\\displaystyle 4+4+4}\n  \n, where 3 is the multiplier, but also as \"3 multiplied by 4\", in which case 3 becomes the multiplicand. One of the main properties of multiplication is the commutative property, which states in this case that adding 3 copies of 4 gives the same result as adding 4 copies of 3. Thus, the designation of multiplier and multiplicand does not affect the result of the multiplication.\n\nSystematic generalizations of this basic definition define the multiplication of integers (including negative numbers), rational numbers (fractions), and real numbers.\nMultiplication can also be visualized as counting objects arranged in a rectangle (for whole numbers) or as finding the area of a rectangle whose sides have some given lengths. The area of a rectangle does not depend on which side is measured first—a consequence of the commutative property.\nThe product of two measurements (or physical quantities) is a new type of measurement (or new quantity), usually with a derived unit of measurement. For example, multiplying the lengths (in meters or feet) of the two sides of a rectangle gives its area (in square meters or square feet). Such a product is the subject of dimensional analysis.\nThe inverse operation of multiplication is division. For example, since 4 multiplied by 3 equals 12, 12 divided by 3 equals 4. Indeed, multiplication by 3, followed by division by 3, yields the original number. The division of a number other than 0 by itself equals 1.\nSeveral mathematical concepts expand upon the fundamental idea of multiplication. The product of a sequence, vector multiplication, complex numbers, and matrices are all examples where this can be seen. These more advanced constructs tend to affect the basic properties in their own ways, such as becoming noncommutative in matrices and some forms of vector multiplication or changing the sign of complex numbers.",
    "Multiplicative inverse": "In mathematics, a multiplicative inverse or reciprocal for a number x, denoted by 1/x or x−1, is a number which when multiplied by x yields the multiplicative identity, 1. The multiplicative inverse of a fraction a/b is b/a. Dividing 1 by a real number yields its multiplicative inverse. For example, the reciprocal of 5 is one fifth (1/5 or 0.2), and the reciprocal of 0.25 is 1 divided by 0.25, or 4. The reciprocal function, the function f(x) that maps x to 1/x, is one of the simplest examples of a function which is its own inverse (an involution).\nMultiplying by a number is the same as dividing by its reciprocal and vice versa. For example, multiplication by 4/5 (or 0.8) will give the same result as division by 5/4 (or 1.25). Therefore, multiplication by a number followed by multiplication by its reciprocal yields the original number (since the product of the number and its reciprocal is 1).\nThe term reciprocal was in common use at least as far back as the third edition of Encyclopædia Britannica (1797) to describe two numbers whose product is 1; geometrical quantities in inverse proportion are described as reciprocall in a 1570 translation of Euclid's Elements.\nIn the phrase multiplicative inverse, the qualifier multiplicative is often omitted and then tacitly understood (in contrast to the additive inverse). Multiplicative inverses can be defined over many mathematical domains as well as numbers. In these cases it can happen that ab ≠ ba; then \"inverse\" typically implies that an element is both a left and right inverse.\nThe notation f −1 is sometimes also used for the inverse function of the function f, which is for most functions not equal to the multiplicative inverse. For example, the multiplicative inverse 1/(sin x) = (sin x)−1 is the cosecant of x, and not the inverse sine of x denoted by sin−1 x or arcsin x. The terminology difference reciprocal versus inverse is not sufficient to make this distinction, since many authors prefer the opposite naming convention, probably for historical reasons (for example in French, the inverse function is preferably called the bijection réciproque).",
    "Division": "Division may refer to:",
    "Quotient": "In arithmetic, a quotient (from Latin: quotiens 'how many times', pronounced ) is a quantity produced by the division of two numbers. The quotient has widespread use throughout mathematics. It has two definitions: either the integer part of a division (in the case of Euclidean division) or a fraction or ratio (in the case of a general division). For example, when dividing 20 (the dividend) by 3 (the divisor), the quotient is 6 (with a remainder of 2) in the first sense and \n  \n    \n      \n        6\n        +\n        \n          \n            \n              2\n              3\n            \n          \n        \n        =\n        6.66...\n      \n    \n    {\\displaystyle 6+{\\tfrac {2}{3}}=6.66...}\n  \n (a repeating decimal) in the second sense.\nIn metrology (International System of Quantities and the International System of Units), \"quotient\" refers to the general case with respect to the units of measurement of physical quantities.\n \nRatios is the special case for dimensionless quotients of two quantities of the same kind.\nQuotients with a non-trivial dimension and compound units, especially when the divisor is a duration (e.g., \"per second\"), are known as rates.\nFor example, density (mass divided by volume, in units of kg/m3) is said to be a \"quotient\", whereas mass fraction (mass divided by mass, in kg/kg or in percent) is a \"ratio\". \nSpecific quantities are intensive quantities resulting from the quotient of a physical quantity by mass, volume, or other measures of the system \"size\".",
    "Quotition and partition": "In arithmetic, quotition and partition are two ways of viewing fractions and division. In quotitive division one asks \"how many parts are there?\" while in partitive division one asks \"what is the size of each part?\"\nIn general, a quotient \n  \n    \n      \n        Q\n        =\n        N\n        \n          /\n        \n        D\n        ,\n      \n    \n    {\\displaystyle Q=N/D,}\n  \n where Q, N, and D are integers or rational numbers, can be conceived of in either of 2 ways:\n\nQuotition: \"How many parts of size D must be added to get a sum of N?\" \n  \n    \n      \n        N\n        =\n        Q\n        ×\n        D\n        =\n        \n          \n            \n              \n                D\n                +\n                D\n                +\n                ⋯\n                +\n                D\n              \n              ⏟\n            \n          \n          \n            Q\n            \n               parts\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle N=Q\\times D=\\underbrace {D+D+\\cdots +D} _{Q{\\text{ parts}}}.}\n  \n\nPartition: \"What is the size of each of D equal parts whose sum is N?\" \n  \n    \n      \n        N\n        =\n        D\n        ×\n        Q\n        =\n        \n          \n            \n              \n                Q\n                +\n                Q\n                +\n                ⋯\n                +\n                Q\n              \n              ⏟\n            \n          \n          \n            D\n            \n               parts\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle N=D\\times Q=\\underbrace {Q+Q+\\cdots +Q} _{D{\\text{ parts}}}.}\n  \n\nFor example, the quotient \n  \n    \n      \n        6\n        \n          /\n        \n        2\n        =\n        3\n      \n    \n    {\\displaystyle 6/2=3}\n  \n can be conceived of as representing either of the decompositions:\n\n  \n    \n      \n        6\n        =\n        \n          \n            \n              \n                2\n                +\n                2\n                +\n                2\n              \n              ⏟\n            \n          \n          \n            3 parts\n          \n        \n        =\n        \n          \n            \n              \n                3\n                +\n                3\n              \n              ⏟\n            \n          \n          \n            2 parts\n          \n        \n        .\n      \n    \n    {\\displaystyle 6=\\underbrace {2+2+2} _{\\text{3 parts}}=\\underbrace {3+3} _{\\text{2 parts}}.}\n  \n\nIn the rational number system used in elementary mathematics, the numerical answer is always the same no matter which way you put it, as a consequence of the commutativity of multiplication.",
    "Fraction": "A fraction (from Latin: fractus, \"broken\") represents a part of a whole or, more generally, any number of equal parts. When spoken in everyday English, a fraction describes how many parts of a certain size there are, for example, one-half, eight-fifths, three-quarters. A common, vulgar, or simple fraction (examples: ⁠1/2⁠ and ⁠17/3⁠) consists of an integer numerator, displayed above a line (or before a slash like 1⁄2), and a non-zero integer denominator, displayed below (or after) that line. If these integers are positive, then the numerator represents a number of equal parts, and the denominator indicates how many of those parts make up a unit or a whole. For example, in the fraction ⁠3/4⁠, the numerator 3 indicates that the fraction represents 3 equal parts, and the denominator 4 indicates that 4 parts make up a whole. The picture to the right illustrates ⁠3/4⁠ of a cake.\nFractions can be used to represent ratios and division. Thus the fraction ⁠3/4⁠ can be used to represent the ratio 3:4 (the ratio of the part to the whole), and the division 3 ÷ 4 (three divided by four).\nWe can also write negative fractions, which represent the opposite of a positive fraction. For example, if ⁠1/2⁠ represents a half-dollar profit, then −⁠1/2⁠ represents a half-dollar loss. Because of the rules of division of signed numbers (which states in part that negative divided by positive is negative), −⁠1/2⁠, ⁠−1/2⁠ and ⁠1/−2⁠ all represent the same fraction –  negative one-half. And because a negative divided by a negative produces a positive, ⁠−1/−2⁠ represents positive one-half.\nIn mathematics a rational number is a number that can be represented by a fraction of the form ⁠a/b⁠, where a and b are integers and b is not zero; the set of all rational numbers is commonly represented by the symbol ⁠\n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n⁠ or Q, which stands for quotient. The term fraction and the notation ⁠a/b⁠ can also be used for mathematical expressions that do not represent a rational number (for example \n  \n    \n      \n        \n          \n            \n              \n                2\n              \n              2\n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle {\\frac {\\sqrt {2}}{2}}}\n  \n), or even do not represent any number (for example the rational fraction \n  \n    \n      \n        \n          \n            \n              1\n              x\n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle {\\frac {1}{x}}}\n  \n).",
    "Proper fraction": "A fraction (from Latin: fractus, \"broken\") represents a part of a whole or, more generally, any number of equal parts. When spoken in everyday English, a fraction describes how many parts of a certain size there are, for example, one-half, eight-fifths, three-quarters. A common, vulgar, or simple fraction (examples: ⁠1/2⁠ and ⁠17/3⁠) consists of an integer numerator, displayed above a line (or before a slash like 1⁄2), and a non-zero integer denominator, displayed below (or after) that line. If these integers are positive, then the numerator represents a number of equal parts, and the denominator indicates how many of those parts make up a unit or a whole. For example, in the fraction ⁠3/4⁠, the numerator 3 indicates that the fraction represents 3 equal parts, and the denominator 4 indicates that 4 parts make up a whole. The picture to the right illustrates ⁠3/4⁠ of a cake.\nFractions can be used to represent ratios and division. Thus the fraction ⁠3/4⁠ can be used to represent the ratio 3:4 (the ratio of the part to the whole), and the division 3 ÷ 4 (three divided by four).\nWe can also write negative fractions, which represent the opposite of a positive fraction. For example, if ⁠1/2⁠ represents a half-dollar profit, then −⁠1/2⁠ represents a half-dollar loss. Because of the rules of division of signed numbers (which states in part that negative divided by positive is negative), −⁠1/2⁠, ⁠−1/2⁠ and ⁠1/−2⁠ all represent the same fraction –  negative one-half. And because a negative divided by a negative produces a positive, ⁠−1/−2⁠ represents positive one-half.\nIn mathematics a rational number is a number that can be represented by a fraction of the form ⁠a/b⁠, where a and b are integers and b is not zero; the set of all rational numbers is commonly represented by the symbol ⁠\n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n⁠ or Q, which stands for quotient. The term fraction and the notation ⁠a/b⁠ can also be used for mathematical expressions that do not represent a rational number (for example \n  \n    \n      \n        \n          \n            \n              \n                2\n              \n              2\n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle {\\frac {\\sqrt {2}}{2}}}\n  \n), or even do not represent any number (for example the rational fraction \n  \n    \n      \n        \n          \n            \n              1\n              x\n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle {\\frac {1}{x}}}\n  \n).",
    "Improper fraction": "A fraction (from Latin: fractus, \"broken\") represents a part of a whole or, more generally, any number of equal parts. When spoken in everyday English, a fraction describes how many parts of a certain size there are, for example, one-half, eight-fifths, three-quarters. A common, vulgar, or simple fraction (examples: ⁠1/2⁠ and ⁠17/3⁠) consists of an integer numerator, displayed above a line (or before a slash like 1⁄2), and a non-zero integer denominator, displayed below (or after) that line. If these integers are positive, then the numerator represents a number of equal parts, and the denominator indicates how many of those parts make up a unit or a whole. For example, in the fraction ⁠3/4⁠, the numerator 3 indicates that the fraction represents 3 equal parts, and the denominator 4 indicates that 4 parts make up a whole. The picture to the right illustrates ⁠3/4⁠ of a cake.\nFractions can be used to represent ratios and division. Thus the fraction ⁠3/4⁠ can be used to represent the ratio 3:4 (the ratio of the part to the whole), and the division 3 ÷ 4 (three divided by four).\nWe can also write negative fractions, which represent the opposite of a positive fraction. For example, if ⁠1/2⁠ represents a half-dollar profit, then −⁠1/2⁠ represents a half-dollar loss. Because of the rules of division of signed numbers (which states in part that negative divided by positive is negative), −⁠1/2⁠, ⁠−1/2⁠ and ⁠1/−2⁠ all represent the same fraction –  negative one-half. And because a negative divided by a negative produces a positive, ⁠−1/−2⁠ represents positive one-half.\nIn mathematics a rational number is a number that can be represented by a fraction of the form ⁠a/b⁠, where a and b are integers and b is not zero; the set of all rational numbers is commonly represented by the symbol ⁠\n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n⁠ or Q, which stands for quotient. The term fraction and the notation ⁠a/b⁠ can also be used for mathematical expressions that do not represent a rational number (for example \n  \n    \n      \n        \n          \n            \n              \n                2\n              \n              2\n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle {\\frac {\\sqrt {2}}{2}}}\n  \n), or even do not represent any number (for example the rational fraction \n  \n    \n      \n        \n          \n            \n              1\n              x\n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle {\\frac {1}{x}}}\n  \n).",
    "Ratio": "In mathematics, a ratio () shows how many times one number contains another. For example, if there are eight oranges and six lemons in a bowl of fruit, then the ratio of oranges to lemons is eight to six (that is, 8:6, which is equivalent to the ratio 4:3). Similarly, the ratio of lemons to oranges is 6:8 (or 3:4) and the ratio of oranges to the total amount of fruit is 8:14 (or 4:7).\nThe numbers in a ratio may be quantities of any kind, such as counts of people or objects, or such as measurements of lengths, weights, time, etc. In most contexts, both numbers are restricted to be positive.\nA ratio may be specified either by giving both constituting numbers, written as \"a to b\" or \"a:b\", or by giving just the value of their quotient ⁠a/b⁠. Equal quotients correspond to equal ratios.\nA statement expressing the equality of two ratios is called a proportion.\nConsequently, a ratio may be considered as an ordered pair of numbers, a fraction with the first number in the numerator and the second in the denominator, or as the value denoted by this fraction. Ratios of counts, given by (non-zero) natural numbers, are rational numbers, and may sometimes be natural numbers. \nA more specific definition adopted in physical sciences (especially in metrology) for ratio is the dimensionless quotient between two physical quantities measured with the same unit. A quotient of two quantities that are measured with different units may be called a rate.",
    "Least common denominator": "In mathematics, the lowest common denominator or least common denominator (abbreviated LCD) is the lowest common multiple of the denominators of a set of fractions. It simplifies adding, subtracting, and comparing fractions.",
    "Factoring": "Factoring can refer to the following:\n\nFactoring (finance), a form of commercial finance\nFactorization, the mathematical concept of splitting an object into multiple parts multiplied together\nInteger factorization, splitting a whole number into the product of smaller whole numbers\nDecomposition (computer science)\nA rule in resolution theorem proving, see Resolution (logic)#Factoring",
    "Prime number": "A prime number (or a prime) is a natural number greater than 1 that is not a product of two smaller natural numbers. A natural number greater than 1 that is not prime is called a composite number. For example, 5 is prime because the only ways of writing it as a product, 1 × 5 or 5 × 1, involve 5 itself. However, 4 is composite because it is a product (2 × 2) in which both numbers are smaller than 4. Primes are central in number theory because of the fundamental theorem of arithmetic: every natural number greater than 1 is either a prime itself or can be factorized as a product of primes that is unique up to their order.\nThe property of being prime is called primality. A simple but slow method of checking the primality of a given number ⁠\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n⁠, called trial division, tests whether ⁠\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n⁠ is a multiple of any integer between 2 and ⁠\n  \n    \n      \n        \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {n}}}\n  \n⁠. Faster algorithms include the Miller–Rabin primality test, which is fast but has a small chance of error, and the AKS primality test, which always produces the correct answer in polynomial time but is too slow to be practical. Particularly fast methods are available for numbers of special forms, such as Mersenne numbers. As of October 2024 the largest known prime number is a Mersenne prime with 41,024,320 decimal digits.\nThere are infinitely many primes, as demonstrated by Euclid around 300 BC. No known simple formula separates prime numbers from composite numbers. However, the distribution of primes within the natural numbers in the large can be statistically modelled. The first result in that direction is the prime number theorem, proven at the end of the 19th century, which says roughly that the probability of a randomly chosen large number being prime is inversely proportional to its number of digits, that is, to its logarithm.\nSeveral historical questions regarding prime numbers are still unsolved. These include Goldbach's conjecture, that every even integer greater than 2 can be expressed as the sum of two primes, and the twin prime conjecture, that there are infinitely many pairs of primes that differ by two. Such questions spurred the development of various branches of number theory, focusing on analytic or algebraic aspects of numbers. Primes are used in several routines in information technology, such as public-key cryptography, which relies on the difficulty of factoring large numbers into their prime factors. In abstract algebra, objects that behave in a generalized way like prime numbers include prime elements and prime ideals.",
    "Distribution of primes": "In mathematics, the prime number theorem (PNT) describes the asymptotic distribution of  prime numbers among the positive integers. It formalizes the intuitive idea that primes become less common as they become larger by precisely quantifying the rate at which this occurs.  The theorem was proved independently by Jacques Hadamard and Charles Jean de la Vallée Poussin in 1896 using ideas introduced by Bernhard Riemann (in particular, the Riemann zeta function).\nThe first such distribution found is π(N) ~ ⁠N/log(N)⁠, where π(N) is the prime-counting function (the number of primes less than or equal to N) and log(N) is the natural logarithm of N. This means that for large enough N, the probability that a random integer not greater than N is prime is very close to 1 / log(N). In other words, the average gap between consecutive prime numbers among the first N integers is roughly log(N). Consequently, a random integer with at most 2n digits (for large enough n) is about half as likely to be prime as a random integer with at most n digits. For example, among the positive integers of at most 1000 digits, about one in 2300 is prime (log(101000) ≈ 2302.6), whereas among positive integers of at most 2000 digits, about one in 4600 is prime (log(102000) ≈ 4605.2).",
    "Composite number": "A composite number is a positive integer that can be formed by multiplying two smaller positive integers. Accordingly it is a positive integer that has at least one divisor other than 1 and itself. Every positive integer is composite, prime, or the unit 1, so the composite numbers are exactly the natural numbers that are not prime and not a unit. E.g., the integer 14 is a composite number because it is the product of the two smaller integers 2 × 7 but the integers 2 and 3 are not because each can only be divided by one and itself.\nThe composite numbers up to 150 are:\n\n4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 102, 104, 105, 106, 108, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 132, 133, 134, 135, 136, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150. (sequence A002808 in the OEIS)\nEvery composite number can be written as the product of two or more (not necessarily distinct) primes. For example, the composite number 299 can be written as 13 × 23, and the composite number 360 can be written as 23 × 32 × 5; furthermore, this representation is unique up to the order of the factors. This fact is called the fundamental theorem of arithmetic.\nThere are several known primality tests that can determine whether a number is prime or composite which do not necessarily reveal the factorization of a composite input.",
    "Factor": "Factor (Latin, 'who/which acts') may refer to:",
    "Euclid's algorithm": "In mathematics, the Euclidean algorithm, or Euclid's algorithm, is an efficient method for computing the greatest common divisor (GCD) of two integers, the largest number that divides them both without a remainder. It is named after the ancient Greek mathematician Euclid, who first described it in his Elements (c. 300 BC).\nIt is an example of an algorithm, and is one of the oldest algorithms in common use. It can be used to reduce fractions to their simplest form, and is a part of many other number-theoretic and cryptographic calculations.\nThe Euclidean algorithm is based on the principle that the greatest common divisor of two numbers does not change if the larger number is replaced by its difference with the smaller number. For example, 21 is the GCD of 252 and 105 (as 252 = 21 × 12 and 105 = 21 × 5), and the same number 21 is also the GCD of 105 and 252 − 105 = 147. Since this replacement reduces the larger of the two numbers, repeating this process gives successively smaller pairs of numbers until the two numbers become equal. When that occurs, that number is the GCD of the original two numbers. By reversing the steps or using the extended Euclidean algorithm, the GCD can be expressed as a linear combination of the two original numbers, that is the sum of the two numbers, each multiplied by an integer (for example, 21 = 5 × 105 + (−2) × 252). The fact that the GCD can always be expressed in this way is known as Bézout's identity.\nThe version of the Euclidean algorithm described above—which follows Euclid's original presentation—may require many subtraction steps to find the GCD when one of the given numbers is much bigger than the other. A more efficient version of the algorithm shortcuts these steps, instead replacing the larger of the two numbers by its remainder when divided by the smaller of the two (with this version, the algorithm stops when reaching a zero remainder). With this improvement, the algorithm never requires more steps than five times the number of digits (base 10) of the smaller integer. This was proven by Gabriel Lamé in 1844 (Lamé's Theorem), and marks the beginning of computational complexity theory. Additional methods for improving the algorithm's efficiency were developed in the 20th century.\nThe Euclidean algorithm has many theoretical and practical applications. It is used for reducing fractions to their simplest form and for performing division in modular arithmetic. Computations using this algorithm form part of the cryptographic protocols that are used to secure internet communications, and in methods for breaking these cryptosystems by factoring large composite numbers. The Euclidean algorithm may be used to solve Diophantine equations, such as finding numbers that satisfy multiple congruences according to the Chinese remainder theorem, to construct continued fractions, and to find accurate rational approximations to real numbers. Finally, it can be used as a basic tool for proving theorems in number theory such as Lagrange's four-square theorem and the uniqueness of prime factorizations.\nThe original algorithm was described only for natural numbers and geometric lengths (real numbers), but the algorithm was generalized in the 19th century to other types of numbers, such as Gaussian integers and polynomials of one variable. This led to modern abstract algebraic notions such as Euclidean domains.",
    "Exponentiation": "In mathematics, exponentiation, denoted bn, is an operation involving two numbers: the base, b, and the exponent or power, n. When n is a positive integer, exponentiation corresponds to repeated multiplication of the base: that is, bn is the product of multiplying n bases:\n\n  \n    \n      \n        \n          b\n          \n            n\n          \n        \n        =\n        \n          \n            \n              \n                b\n                ×\n                b\n                ×\n                ⋯\n                ×\n                b\n                ×\n                b\n              \n              ⏟\n            \n          \n          \n            n\n            \n               times\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle b^{n}=\\underbrace {b\\times b\\times \\dots \\times b\\times b} _{n{\\text{ times}}}.}\n  \nIn particular, \n  \n    \n      \n        \n          b\n          \n            1\n          \n        \n        =\n        b\n      \n    \n    {\\displaystyle b^{1}=b}\n  \n.\nThe exponent is usually shown as a superscript to the right of the base as bn or in computer code as b^n. This binary operation is often read as \"b to the power n\"; it may also be referred to as \"b raised to the nth power\", \"the nth power of b\", or, most briefly, \"b to the n\".\nThe above definition of \n  \n    \n      \n        \n          b\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle b^{n}}\n  \n immediately implies several properties, in particular the multiplication rule:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  b\n                  \n                    n\n                  \n                \n                ×\n                \n                  b\n                  \n                    m\n                  \n                \n              \n              \n                \n                =\n                \n                  \n                    \n                      \n                        b\n                        ×\n                        ⋯\n                        ×\n                        b\n                      \n                      ⏟\n                    \n                  \n                  \n                    n\n                    \n                       times\n                    \n                  \n                \n                ×\n                \n                  \n                    \n                      \n                        b\n                        ×\n                        ⋯\n                        ×\n                        b\n                      \n                      ⏟\n                    \n                  \n                  \n                    m\n                    \n                       times\n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  \n                    \n                      \n                        b\n                        ×\n                        ⋯\n                        ×\n                        b\n                      \n                      ⏟\n                    \n                  \n                  \n                    n\n                    +\n                    m\n                    \n                       times\n                    \n                  \n                \n                =\n                \n                  b\n                  \n                    n\n                    +\n                    m\n                  \n                \n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}b^{n}\\times b^{m}&=\\underbrace {b\\times \\dots \\times b} _{n{\\text{ times}}}\\times \\underbrace {b\\times \\dots \\times b} _{m{\\text{ times}}}\\\\[1ex]&=\\underbrace {b\\times \\dots \\times b} _{n+m{\\text{ times}}}=b^{n+m}.\\end{aligned}}}\n  \n\nThat is, when multiplying a base raised to one power times the same base raised to another power, the powers add. \nExponentiation can also be extended to powers that are not positive integers.  When b is non-zero, the definition \n  \n    \n      \n        \n          b\n          \n            0\n          \n        \n        =\n        1\n      \n    \n    {\\displaystyle b^{0}=1}\n  \n\nis compatible with the multiplication rule: \n  \n    \n      \n        \n          b\n          \n            0\n          \n        \n        ×\n        \n          b\n          \n            n\n          \n        \n        =\n        \n          b\n          \n            0\n            +\n            n\n          \n        \n        =\n        \n          b\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle b^{0}\\times b^{n}=b^{0+n}=b^{n}}\n  \n.  A similar argument suggests the definition\n\n  \n    \n      \n        \n          b\n          \n            −\n            n\n          \n        \n        =\n        1\n        \n          /\n        \n        \n          b\n          \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle b^{-n}=1/b^{n},}\n  \n\nfor negative integer powers, and in particular \n  \n    \n      \n        \n          b\n          \n            −\n            1\n          \n        \n        =\n        \n          \n            1\n            b\n          \n        \n      \n    \n    {\\displaystyle b^{-1}={\\frac {1}{b}}}\n  \n for any nonzero number b, and also the definition\n\n  \n    \n      \n        \n          b\n          \n            n\n            \n              /\n            \n            m\n          \n        \n        =\n        \n          \n            \n              b\n              \n                n\n              \n            \n            \n              m\n            \n          \n        \n      \n    \n    {\\displaystyle b^{n/m}={\\sqrt[{m}]{b^{n}}}}\n  \n\nfor fractional powers (when m and n are both integers).  For example, \n  \n    \n      \n        \n          b\n          \n            1\n            \n              /\n            \n            2\n          \n        \n        ×\n        \n          b\n          \n            1\n            \n              /\n            \n            2\n          \n        \n        =\n        \n          b\n          \n            1\n            \n              /\n            \n            2\n            +\n            1\n            \n              /\n            \n            2\n          \n        \n        =\n        \n          b\n          \n            1\n          \n        \n        =\n        b\n      \n    \n    {\\displaystyle b^{1/2}\\times b^{1/2}=b^{1/2+1/2}=b^{1}=b}\n  \n, meaning \n  \n    \n      \n        (\n        \n          b\n          \n            1\n            \n              /\n            \n            2\n          \n        \n        \n          )\n          \n            2\n          \n        \n        =\n        b\n      \n    \n    {\\displaystyle (b^{1/2})^{2}=b}\n  \n, which is the definition of square root: \n  \n    \n      \n        \n          b\n          \n            1\n            \n              /\n            \n            2\n          \n        \n        =\n        \n          \n            b\n          \n        \n      \n    \n    {\\displaystyle b^{1/2}={\\sqrt {b}}}\n  \n.\nThe definition of exponentiation can be extended in a natural way (preserving the multiplication rule) to define \n  \n    \n      \n        \n          b\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle b^{x}}\n  \n for any positive real base \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n and any real number exponent \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n. More involved definitions allow complex base and exponent, as well as certain types of matrices as base or exponent.\nExponentiation is used extensively in many fields, including economics, biology, chemistry, physics, and computer science, with applications such as compound interest, population growth, chemical reaction kinetics, wave behavior, and public-key cryptography.",
    "Cube root": "In mathematics, a cube root of a number x is a number y that has the given number as its third power; that is \n  \n    \n      \n        \n          y\n          \n            3\n          \n        \n        =\n        x\n        .\n      \n    \n    {\\displaystyle y^{3}=x.}\n  \n The number of cube roots of a number depends on the number system that is considered.\nEvery real number x has exactly one real cube root that is denoted \n  \n    \n      \n        \n          \n            x\n            \n              3\n            \n          \n        \n      \n    \n    {\\textstyle {\\sqrt[{3}]{x}}}\n  \n and called the real cube root of x or simply the cube root of x in contexts where complex numbers are not considered. For example, the real cube roots of 8 and −8 are respectively 2 and −2. The real cube root of an integer or of a rational number is generally not a rational number, neither a constructible number.\nEvery nonzero real or complex number has exactly three cube roots that are complex numbers. If the number is real, one of the cube roots is real and the two other are nonreal complex conjugate numbers. Otherwise, the three cube roots are all nonreal. For example, the real cube root of 8 is 2 and the other cube roots of 8 are \n  \n    \n      \n        −\n        1\n        +\n        i\n        \n          \n            3\n          \n        \n      \n    \n    {\\displaystyle -1+i{\\sqrt {3}}}\n  \n and \n  \n    \n      \n        −\n        1\n        −\n        i\n        \n          \n            3\n          \n        \n      \n    \n    {\\displaystyle -1-i{\\sqrt {3}}}\n  \n. The three cube roots of −27i are  \n\n  \n    \n      \n        3\n        i\n        ,\n        \n          \n            \n              \n                3\n                \n                  \n                    3\n                  \n                \n              \n              2\n            \n          \n        \n        −\n        \n          \n            \n              3\n              2\n            \n          \n        \n        i\n        ,\n      \n    \n    {\\displaystyle 3i,{\\tfrac {3{\\sqrt {3}}}{2}}-{\\tfrac {3}{2}}i,}\n  \n and \n  \n    \n      \n        −\n        \n          \n            \n              \n                3\n                \n                  \n                    3\n                  \n                \n              \n              2\n            \n          \n        \n        −\n        \n          \n            \n              3\n              2\n            \n          \n        \n        i\n        .\n      \n    \n    {\\displaystyle -{\\tfrac {3{\\sqrt {3}}}{2}}-{\\tfrac {3}{2}}i.}\n  \n The number zero has a unique cube root, which is zero itself.\nThe cube root is a multivalued function. The principal cube root is its principal value, that is a unique cube root that has been chosen once for all. The principal cube root is the cube root with the largest real part. In the case of negative real numbers, the largest real part is shared by the two nonreal cube roots, and the principal cube root is the one with positive imaginary part. So, for negative real numbers, the real cube root is not the principal cube root. For positive real numbers, the principal cube root is the real cube root.\nIf y is any cube root of the complex number x, the other cube roots are \n  \n    \n      \n        y\n        \n        \n          \n            \n              \n                −\n                1\n                +\n                i\n                \n                  \n                    3\n                  \n                \n              \n              2\n            \n          \n        \n      \n    \n    {\\displaystyle y\\,{\\tfrac {-1+i{\\sqrt {3}}}{2}}}\n  \n and \n  \n    \n      \n        y\n        \n        \n          \n            \n              \n                −\n                1\n                −\n                i\n                \n                  \n                    3\n                  \n                \n              \n              2\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle y\\,{\\tfrac {-1-i{\\sqrt {3}}}{2}}.}\n  \n\nIn an algebraically closed field of characteristic different from three, every nonzero element has exactly three cube roots, which can be obtained from any of them by multiplying it by either root of the polynomial \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        +\n        x\n        +\n        1.\n      \n    \n    {\\displaystyle x^{2}+x+1.}\n  \n In an algebraically closed field of characteristic three, every element has exactly one cube root.\nIn other number systems or other algebraic structures, a number or element may have more than three cube roots. For example, in the quaternions, a real number has infinitely many cube roots.",
    "Associative property": "In mathematics, the associative property is a property of some binary operations that rearranging the parentheses in an expression will not change the result. In propositional logic, associativity is a valid rule of replacement for expressions in logical proofs.\nWithin an expression containing two or more occurrences in a row of the same associative operator, the order in which the operations are performed does not matter as long as the sequence of the operands is not changed. That is (after rewriting the expression with parentheses and in infix notation if necessary), rearranging the parentheses in such an expression will not change its value. Consider the following equations:\n\n  \n    \n      \n        \n          \n            \n              \n                (\n                2\n                +\n                3\n                )\n                +\n                4\n              \n              \n                \n                =\n                2\n                +\n                (\n                3\n                +\n                4\n                )\n                =\n                9\n                \n              \n            \n            \n              \n                2\n                ×\n                (\n                3\n                ×\n                4\n                )\n              \n              \n                \n                =\n                (\n                2\n                ×\n                3\n                )\n                ×\n                4\n                =\n                24.\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}(2+3)+4&=2+(3+4)=9\\,\\\\2\\times (3\\times 4)&=(2\\times 3)\\times 4=24.\\end{aligned}}}\n  \n\nEven though the parentheses were rearranged on each line, the values of the expressions were not altered. Since this holds true when performing addition and multiplication on any real numbers, it can be said that \"addition and multiplication of real numbers are associative operations\".\nAssociativity is not the same as commutativity, which addresses whether the order of two operands affects the result. For example, the order does not matter in the multiplication of real numbers, that is, a × b = b × a, so we say that the multiplication of real numbers is a commutative operation. However, operations such as function composition and matrix multiplication are associative, but not (generally) commutative.\nAssociative operations are abundant in mathematics; in fact, many algebraic structures (such as semigroups and categories) explicitly require their binary operations to be associative.  However, many important and interesting operations are non-associative; some examples include subtraction, exponentiation, and the vector cross product. In contrast to the theoretical properties of real numbers, the addition of floating point numbers in computer science is not associative, and the choice of how to associate an expression can have a significant effect on rounding error.",
    "Distributive property": "In mathematics, the distributive property of binary operations is a generalization of the distributive law, which asserts that the equality\n\n  \n    \n      \n        x\n        ⋅\n        (\n        y\n        +\n        z\n        )\n        =\n        x\n        ⋅\n        y\n        +\n        x\n        ⋅\n        z\n      \n    \n    {\\displaystyle x\\cdot (y+z)=x\\cdot y+x\\cdot z}\n  \n\nis always true in elementary algebra.\nFor example, in elementary arithmetic, one has\n\n  \n    \n      \n        2\n        ⋅\n        (\n        1\n        +\n        3\n        )\n        =\n        (\n        2\n        ⋅\n        1\n        )\n        +\n        (\n        2\n        ⋅\n        3\n        )\n        .\n      \n    \n    {\\displaystyle 2\\cdot (1+3)=(2\\cdot 1)+(2\\cdot 3).}\n  \n\nTherefore, one would say that multiplication distributes over addition.\nThis basic property of numbers is part of the definition of most algebraic structures that have two operations called addition and multiplication, such as complex numbers, polynomials, matrices, rings, and fields. It is also encountered in Boolean algebra and mathematical logic, where each of the logical and (denoted \n  \n    \n      \n        \n        ∧\n        \n      \n    \n    {\\displaystyle \\,\\land \\,}\n  \n) and the logical or (denoted \n  \n    \n      \n        \n        ∨\n        \n      \n    \n    {\\displaystyle \\,\\lor \\,}\n  \n) distributes over the other.",
    "Commutative property": "In mathematics, a binary operation is commutative if changing the order of the operands does not change the result. It is a fundamental property of many binary operations, and many mathematical proofs depend on it. Perhaps most familiar as a property of arithmetic, e.g. \"3 + 4 = 4 + 3\" or \"2 × 5 = 5 × 2\", the property can also be used in more advanced settings. The name is needed because there are operations, such as division and subtraction, that do not have it (for example, \"3 − 5 ≠ 5 − 3\"); such operations are not commutative, and so are referred to as noncommutative operations.\nThe idea that simple operations, such as the multiplication and addition of numbers, are commutative was for many centuries implicitly assumed. Thus, this property was not named until the 19th century, when new algebraic structures started to be studied.",
    "Factorial": "In mathematics, the factorial of a non-negative integer \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n, denoted by \n  \n    \n      \n        n\n        !\n      \n    \n    {\\displaystyle n!}\n  \n, is the product of all positive integers less than or equal to \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n. The factorial of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n also equals the product of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n with the next smaller factorial:\n\n  \n    \n      \n        \n          \n            \n              \n                n\n                !\n              \n              \n                \n                =\n                n\n                ×\n                (\n                n\n                −\n                1\n                )\n                ×\n                (\n                n\n                −\n                2\n                )\n                ×\n                (\n                n\n                −\n                3\n                )\n                ×\n                ⋯\n                ×\n                3\n                ×\n                2\n                ×\n                1\n              \n            \n            \n              \n              \n                \n                =\n                n\n                ×\n                (\n                n\n                −\n                1\n                )\n                !\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}n!&=n\\times (n-1)\\times (n-2)\\times (n-3)\\times \\cdots \\times 3\\times 2\\times 1\\\\&=n\\times (n-1)!\\\\\\end{aligned}}}\n  \n\nFor example,\n\n  \n    \n      \n        5\n        !\n        =\n        5\n        ×\n        4\n        !\n        =\n        5\n        ×\n        4\n        ×\n        3\n        ×\n        2\n        ×\n        1\n        =\n        120.\n      \n    \n    {\\displaystyle 5!=5\\times 4!=5\\times 4\\times 3\\times 2\\times 1=120.}\n  \n\nThe value of 0! is 1, according to the convention for an empty product.\nFactorials have been discovered in several ancient cultures, notably in Indian mathematics in the canonical works of Jain literature, and by Jewish mystics in the Talmudic book Sefer Yetzirah. The factorial operation is encountered in many areas of mathematics, notably in combinatorics, where its most basic use counts the possible distinct sequences – the permutations – of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n distinct objects: there are \n  \n    \n      \n        n\n        !\n      \n    \n    {\\displaystyle n!}\n  \n. In mathematical analysis, factorials are used in power series for the exponential function and other functions, and they also have applications in algebra, number theory, probability theory, and computer science.\nMuch of the mathematics of the factorial function was developed beginning in the late 18th and early 19th centuries.\nStirling's approximation provides an accurate approximation to the factorial of large numbers, showing that it grows more quickly than exponential growth. Legendre's formula describes the exponents of the prime numbers in a prime factorization of the factorials, and can be used to count the trailing zeros of the factorials. Daniel Bernoulli and Leonhard Euler interpolated the factorial function to a continuous function of complex numbers, except at the negative integers, the (offset) gamma function.\nMany other notable functions and number sequences are closely related to the factorials, including the binomial coefficients, double factorials, falling factorials, primorials, and subfactorials. Implementations of the factorial function are commonly used as an example of different computer programming styles, and are included in scientific calculators and scientific computing software libraries. Although directly computing large factorials using the product formula or recurrence is not efficient, faster algorithms are known, matching to within a constant factor the time for fast multiplication algorithms for numbers with the same number of digits.",
    "Real number": "In mathematics, a real number is a number that can be used to measure a continuous one-dimensional quantity such as a length, duration or temperature. Here, continuous means that pairs of values can have arbitrarily small differences. Every real number can be almost uniquely represented by an infinite decimal expansion.\nThe real numbers are fundamental in calculus (and in many other branches of mathematics), in particular by their role in the classical definitions of limits, continuity and derivatives.\nThe set of real numbers, sometimes called \"the reals\", is traditionally denoted by a bold R, often using blackboard bold, ⁠\n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n⁠.\nThe adjective real, used in the 17th century by René Descartes, distinguishes real numbers from imaginary numbers such as the square roots of −1.\nThe real numbers include the rational numbers, such as the integer −5 and the fraction 4 / 3. The rest of the real numbers are called irrational numbers. Some irrational numbers (as well as all the rationals) are the root of a polynomial with integer coefficients, such as the square root √2 = 1.414...; these are called algebraic numbers. There are also real numbers which are not, such as π = 3.1415...; these are called transcendental numbers.\n\nReal numbers can be thought of as all points on a line called the number line or real line, where the points corresponding to integers (..., −2, −1, 0, 1, 2, ...) are equally spaced.\nThe informal descriptions above of the real numbers are not sufficient for ensuring the correctness of proofs of theorems involving real numbers. The realization that a better definition was needed, and the elaboration of such a definition was a major development of 19th-century mathematics and is the foundation of real analysis, the study of real functions and real-valued sequences. A current axiomatic definition is that real numbers form the unique (up to an isomorphism) Dedekind-complete ordered field. Other common definitions of real numbers include equivalence classes of Cauchy sequences (of rational numbers), Dedekind cuts, and infinite decimal representations. All these definitions satisfy the axiomatic definition and are thus equivalent.",
    "Irrational number": "In mathematics, the irrational numbers are all the real numbers that are not rational numbers. That is, irrational numbers cannot be expressed as the ratio of two integers. When the ratio of lengths of two line segments is an irrational number, the line segments are also described as being incommensurable, meaning that they share no \"measure\" in common, that is, there is no length (\"the measure\"), no matter how short, that could be used to express the lengths of both of the two given segments as integer multiples of itself.\nAmong irrational numbers are the ratio π of a circle's circumference to its diameter, Euler's number e, the golden ratio φ, and the square root of two.  In fact, all square roots of natural numbers, other than of perfect squares, are irrational.\nLike all real numbers, irrational numbers can be expressed in positional notation, notably as a decimal number. In the case of irrational numbers, the decimal expansion does not terminate, nor end with a repeating sequence. For example, the decimal representation of π starts with 3.14159, but no finite number of digits can represent π exactly, nor does it repeat. Conversely, a decimal expansion that terminates or repeats must be a rational number. These are provable properties of rational numbers and positional number systems and are not used as definitions in mathematics.\nIrrational numbers can also be expressed as non-terminating continued fractions (which in some cases are periodic), and in many other ways.\nAs a consequence of Cantor's proof that the real numbers are uncountable and the rationals countable, it follows that almost all real numbers are irrational.",
    "Odd number": "In mathematics, parity is the property of an integer of whether it is even or odd. An integer is even if it is divisible by 2, and odd if it is not. For example, −4, 0, and 82 are even numbers, while −3, 5, 23, and 67 are odd numbers.\nThe above definition of parity applies only to integer numbers, hence it cannot be applied to numbers with decimals or fractions like 1/2 or 4.6978. See the section \"Higher mathematics\" below for some extensions of the notion of parity to a larger class of \"numbers\" or in other more general settings.\nEven and odd numbers have opposite parities, e.g., 22 (even number) and 13 (odd number) have opposite parities. In particular, the parity of zero is even. Any two consecutive integers have opposite parity. A number (i.e., integer) expressed in the decimal numeral system is even or odd according to whether its last digit is even or odd. That is, if the last digit is 1, 3, 5, 7, or 9, then it is odd; otherwise it is even—as the last digit of any even number is 0, 2, 4, 6, or 8. The same idea will work using any even base. In particular, a number expressed in the binary numeral system is odd if its last digit is 1; and it is even if its last digit is 0. In an odd base, the number is even according to the sum of its digits—it is even if and only if the sum of its digits is even.",
    "Even number": "In mathematics, parity is the property of an integer of whether it is even or odd. An integer is even if it is divisible by 2, and odd if it is not. For example, −4, 0, and 82 are even numbers, while −3, 5, 23, and 67 are odd numbers.\nThe above definition of parity applies only to integer numbers, hence it cannot be applied to numbers with decimals or fractions like 1/2 or 4.6978. See the section \"Higher mathematics\" below for some extensions of the notion of parity to a larger class of \"numbers\" or in other more general settings.\nEven and odd numbers have opposite parities, e.g., 22 (even number) and 13 (odd number) have opposite parities. In particular, the parity of zero is even. Any two consecutive integers have opposite parity. A number (i.e., integer) expressed in the decimal numeral system is even or odd according to whether its last digit is even or odd. That is, if the last digit is 1, 3, 5, 7, or 9, then it is odd; otherwise it is even—as the last digit of any even number is 0, 2, 4, 6, or 8. The same idea will work using any even base. In particular, a number expressed in the binary numeral system is odd if its last digit is 1; and it is even if its last digit is 0. In an odd base, the number is even according to the sum of its digits—it is even if and only if the sum of its digits is even.",
    "Positive number": "In mathematics, the sign of a real number is its property of being either positive, negative, or 0. Depending on local conventions, zero may be considered as having its own unique sign, having no sign, or having both positive and negative sign. In some contexts, it makes sense to distinguish between a positive and a negative zero. \nIn mathematics and physics, the phrase \"change of sign\" is associated with exchanging an object for its additive inverse (multiplication with −1, negation), an operation which is not restricted to real numbers. It applies among other objects to vectors, matrices, and complex numbers, which are not prescribed to be only either positive, negative, or zero. \nThe word \"sign\" is also often used to indicate binary aspects of mathematical or scientific objects, such as odd and even (sign of a permutation), sense of orientation or rotation (cw/ccw), one sided limits, and other concepts described in § Other meanings below.",
    "Negative number": "In mathematics, a negative number is the opposite of a positive real number. Equivalently, a negative number is a real number that is less than zero. Negative numbers are often used to represent the magnitude of a loss or deficiency. A debt that is owed may be thought of as a negative asset. If a quantity, such as the charge on an electron, may have either of two opposite senses, then one may choose to distinguish between those senses—perhaps arbitrarily—as positive and negative. Negative numbers are used to describe values on a scale that goes below zero, such as the Celsius and Fahrenheit scales for temperature. The laws of arithmetic for negative numbers ensure that the common-sense idea of an opposite is reflected in arithmetic. For example, −‍(−3) = 3 because the opposite of an opposite is the original value.\nNegative numbers are usually written with a minus sign in front. For example, −3 represents a negative quantity with a magnitude of three, and is pronounced and read as \"minus three\" or \"negative three\". Conversely, a number that is greater than zero is called positive; zero is usually (but not always) thought of as neither positive nor negative. The positivity of a number may be emphasized by placing a plus sign before it, e.g. +3. In general, the negativity or positivity of a number is referred to as its sign.\nEvery real number other than zero is either positive or negative. The non-negative whole numbers are referred to as natural numbers (i.e., 0, 1, 2, 3, ...), while the positive and negative whole numbers (together with zero) are referred to as integers. (Some definitions of the natural numbers exclude zero.)\nIn bookkeeping, amounts owed are often represented by red numbers, or a number in parentheses, as an alternative notation to represent negative numbers.\nNegative numbers were used in the Nine Chapters on the Mathematical Art, which in its present form dates from the period of the Chinese Han dynasty (202 BC – AD 220), but may well contain much older material. Liu Hui (c. 3rd century) established rules for adding and subtracting negative numbers. By the 7th century, Indian mathematicians such as Brahmagupta were describing the use of negative numbers. Islamic mathematicians further developed the rules of subtracting and multiplying negative numbers and solved problems with negative coefficients. Prior to the concept of negative numbers, mathematicians such as Diophantus considered negative solutions to problems \"false\" and equations requiring negative solutions were described as absurd. Western mathematicians like Leibniz held that negative numbers were invalid, but still used them in calculations.",
    "Highly composite number": "A highly composite number is a positive integer that has more divisors than all smaller positive integers. If d(n) denotes the number of divisors of a positive integer n, then a positive integer N is highly composite if d(N) > d(n) for all n < N. For example, 6 is highly composite because d(6) = 4, and for n = 1,2,3,4,5, you get d(n) = 1,2,2,3,2, respectively, which are all less than 4. \nA related concept is that of a largely composite number, a positive integer that has at least as many divisors as all smaller positive integers. The name can be somewhat misleading, as the first two highly composite numbers (1 and 2) are not actually composite numbers; however, all further terms are.\nRamanujan wrote a paper on highly composite numbers in 1915.\nThe mathematician Jean-Pierre Kahane suggested that Plato must have known about highly composite numbers as he deliberately chose such a number, 5040 (= 7!), as the ideal number of citizens in a city. Furthermore, Vardoulakis and Pugh's paper delves into a similar inquiry concerning the number 5040.",
    "Perfect number": "In number theory, a perfect number is a positive integer that is equal to the sum of its positive proper divisors, that is, divisors excluding the number itself. For instance, 6 has proper divisors 1, 2, and 3, and 1 + 2 + 3 = 6, so 6 is a perfect number. The next perfect number is 28, because 1 + 2 + 4 + 7 + 14 = 28.\nThe first seven perfect numbers are 6, 28, 496, 8128, 33550336, 8589869056, and 137438691328.\nThe sum of proper divisors of a number is called its aliquot sum, so a perfect number is one that is equal to its aliquot sum. Equivalently, a perfect number is a number that is half the sum of all of its positive divisors; in symbols, \n  \n    \n      \n        \n          σ\n          \n            1\n          \n        \n        (\n        n\n        )\n        =\n        2\n        n\n      \n    \n    {\\displaystyle \\sigma _{1}(n)=2n}\n  \n where \n  \n    \n      \n        \n          σ\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\sigma _{1}}\n  \n is the sum-of-divisors function.\nThis definition is ancient, appearing as early as Euclid's Elements (VII.22) where it is called τέλειος ἀριθμός (perfect, ideal, or complete number). Euclid also proved a formation rule (IX.36) whereby \n  \n    \n      \n        \n          \n            \n              q\n              (\n              q\n              +\n              1\n              )\n            \n            2\n          \n        \n      \n    \n    {\\textstyle {\\frac {q(q+1)}{2}}}\n  \n is an even perfect number whenever \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n  \n is a prime of the form \n  \n    \n      \n        \n          2\n          \n            p\n          \n        \n        −\n        1\n      \n    \n    {\\displaystyle 2^{p}-1}\n  \n for positive integer \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n—what is now called a Mersenne prime. Two millennia later, Leonhard Euler proved that all even perfect numbers are of this form. This is known as the Euclid–Euler theorem.\nIt is not known whether there are any odd perfect numbers, nor whether infinitely many perfect numbers exist.",
    "Algebraic number": "In mathematics, an algebraic number is a number that is a root of a non-zero polynomial in one variable with integer (or, equivalently, rational) coefficients.  For example, the golden ratio \n  \n    \n      \n        (\n        1\n        +\n        \n          \n            5\n          \n        \n        )\n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle (1+{\\sqrt {5}})/2}\n  \n is an algebraic number, because it is a root of the polynomial \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        −\n        x\n        −\n        1\n      \n    \n    {\\displaystyle x^{2}-x-1}\n  \n, i.e., a solution to the equation \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        −\n        x\n        −\n        1\n        =\n        0\n      \n    \n    {\\displaystyle x^{2}-x-1=0}\n  \n, and the complex number \n  \n    \n      \n        1\n        +\n        i\n      \n    \n    {\\displaystyle 1+i}\n  \n is algebraic because it is a root of the polynomial \n  \n    \n      \n        \n          x\n          \n            4\n          \n        \n        +\n        4\n      \n    \n    {\\displaystyle x^{4}+4}\n  \n. Algebraic numbers include all integers, rational numbers, and n-th roots of integers.\nAlgebraic complex numbers are closed under addition, subtraction, multiplication and division, and hence form a field, denoted \n  \n    \n      \n        \n          \n            \n              Q\n            \n            ¯\n          \n        \n      \n    \n    {\\displaystyle {\\overline {\\mathbb {Q} }}}\n  \n. The set of algebraic real numbers \n  \n    \n      \n        \n          \n            \n              Q\n            \n            ¯\n          \n        \n        ∩\n        \n          R\n        \n      \n    \n    {\\displaystyle {\\overline {\\mathbb {Q} }}\\cap \\mathbb {R} }\n  \n is also a field.\nNumbers which are not algebraic are called transcendental and include π and e. There are countably infinite algebraic numbers, hence almost all real (or complex) numbers (in the sense of Lebesgue measure) are transcendental.",
    "Transcendental number": "In mathematics, a transcendental number is a real or complex number that is not algebraic: that is, not the root of a non-zero polynomial with integer (or, equivalently, rational) coefficients. The best-known transcendental numbers are π and e. The quality of a number being transcendental is called transcendence.\nThough only a few classes of transcendental numbers are known, partly because it can be extremely difficult to show that a given number is transcendental, transcendental numbers are not rare: indeed, almost all real and complex numbers are transcendental, since the algebraic numbers form a countable set, while the set of real numbers ⁠\n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n⁠ and the set of complex numbers ⁠\n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n⁠ are both uncountable sets, and therefore larger than any countable set.\nAll transcendental real numbers (also known as real transcendental numbers or transcendental irrational numbers) are irrational numbers, since all rational numbers are algebraic. The converse is not true: Not all irrational numbers are transcendental. Hence, the set of real numbers consists of non-overlapping sets of rational, algebraic irrational, and transcendental real numbers. For example, the square root of 2 is an irrational number, but it is not a transcendental number as it is a root of the polynomial equation x2 − 2 = 0. The golden ratio (denoted \n  \n    \n      \n        φ\n      \n    \n    {\\displaystyle \\varphi }\n  \n or \n  \n    \n      \n        ϕ\n      \n    \n    {\\displaystyle \\phi }\n  \n) is another irrational number that is not transcendental, as it is a root of the polynomial equation x2 − x − 1 = 0.",
    "Hypercomplex number": "In mathematics, hypercomplex number is a traditional term for an element of a finite-dimensional unital algebra over the field of real numbers. \nThe study of hypercomplex numbers in the late 19th century forms the basis of modern group representation theory.",
    "Transfinite number": "In mathematics, transfinite numbers or infinite numbers are numbers that are \"infinite\" in the sense that they are larger than all finite numbers. These include the transfinite cardinals, which are cardinal numbers used to quantify the size of infinite sets, and the transfinite ordinals, which are ordinal numbers used to provide an ordering of infinite sets. The term transfinite was coined in 1895 by Georg Cantor, who wished to avoid some of the implications of the word infinite.  In particular he believed that \"truly infinite\" is a perfect and thus divine quality and so refused to attribute this term to mathematical constructs comprehensible by humans. Few contemporary writers share these qualms; it is now accepted usage to refer to transfinite cardinals and ordinals as infinite numbers. Nevertheless, the term transfinite also remains in use.\nNotable work on transfinite numbers was done by Wacław Sierpiński: Leçons sur les nombres transfinis (1928 book) much expanded into Cardinal and Ordinal Numbers (1958, 2nd ed. 1965).",
    "Indefinite and fictitious numbers": "Indefinite and fictitious numbers are words, phrases and quantities used to describe an indefinite size, used for comic effect, for exaggeration, as placeholder names, or when precision is unnecessary or undesirable. Other descriptions of this concept include: \"non-numerical vague quantifier\" and \"indefinite hyperbolic numerals\".",
    "Mean": "A mean is a quantity representing the \"center\" of a collection of numbers and is intermediate to the extreme values of the set of numbers. There are several kinds of means (or \"measures of central tendency\") in mathematics, especially in statistics. Each attempts to summarize or typify a given group of data, illustrating the magnitude and sign of the data set. Which of these measures is most illuminating depends on what is being measured, and on context and purpose.\nThe arithmetic mean, also known as \"arithmetic average\", is the sum of the values divided by the number of values. The arithmetic mean of a set of numbers x1, x2, ..., xn is typically denoted using an overhead bar, \n  \n    \n      \n        \n          \n            \n              x\n              ¯\n            \n          \n        \n      \n    \n    {\\displaystyle {\\bar {x}}}\n  \n. If the numbers are from observing a sample of a larger group, the arithmetic mean is termed the sample mean (\n  \n    \n      \n        \n          \n            \n              x\n              ¯\n            \n          \n        \n      \n    \n    {\\displaystyle {\\bar {x}}}\n  \n) to distinguish it from the group mean (or expected value) of the underlying distribution, denoted \n  \n    \n      \n        μ\n      \n    \n    {\\displaystyle \\mu }\n  \n or \n  \n    \n      \n        \n          μ\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle \\mu _{x}}\n  \n.\nOutside probability and statistics, a wide range of other notions of mean are often used in geometry and mathematical analysis; examples are given below.",
    "Median": "The median of a set of numbers is the value separating the higher half from the lower half of a data sample, a population, or a probability distribution. For a data set, it may be thought of as the “middle\" value. The basic feature of the median in describing data compared to the mean (often simply described as the \"average\") is that it is not skewed by a small proportion of extremely large or small values, and therefore provides a better representation of the center. Median income, for example, may be a better way to describe the center of the income distribution because increases in the largest incomes alone have no effect on the median. For this reason, the median is of central importance in robust statistics.\nMedian is a 2-quantile; it is the value that partitions a set into two equal parts.",
    "Mode": "Mode (Latin: modus meaning \"manner, tune, measure, due measure, rhythm, melody\") may refer to:",
    "Range": "Range may refer to:",
    "Combinations": "In mathematics, a combination is a selection of items from a set that has distinct members, such that the order of selection does not matter (unlike permutations). For example, given three fruits, say an apple, an orange and a pear, there are three combinations of two that can be drawn from this set: an apple and a pear; an apple and an orange; or a pear and an orange. More formally, a k-combination of a set S is a subset of k distinct elements of S. So, two combinations are identical if and only if each combination has the same members. (The arrangement of the members in each set does not matter.) If the set has n elements, the number of k-combinations, denoted by \n  \n    \n      \n        C\n        (\n        n\n        ,\n        k\n        )\n      \n    \n    {\\displaystyle C(n,k)}\n  \n or \n  \n    \n      \n        \n          C\n          \n            k\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle C_{k}^{n}}\n  \n, is equal to the binomial coefficient:\n\n  \n    \n      \n        \n          \n            \n              (\n            \n            \n              n\n              k\n            \n            \n              )\n            \n          \n        \n        =\n        \n          \n            \n              n\n              (\n              n\n              −\n              1\n              )\n              ⋯\n              (\n              n\n              −\n              k\n              +\n              1\n              )\n            \n            \n              k\n              (\n              k\n              −\n              1\n              )\n              ⋯\n              1\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\binom {n}{k}}={\\frac {n(n-1)\\dotsb (n-k+1)}{k(k-1)\\dotsb 1}},}\n  \n\nwhich using factorial notation can be compactly expressed as\n\n  \n    \n      \n        \n          \n            \n              (\n            \n            \n              n\n              k\n            \n            \n              )\n            \n          \n        \n        =\n        \n          \n            \n              n\n              !\n            \n            \n              k\n              !\n              (\n              n\n              −\n              k\n              )\n              !\n            \n          \n        \n      \n    \n    {\\displaystyle {\\binom {n}{k}}={\\frac {n!}{k!(n-k)!}}}\n  \n\nwhenever \n  \n    \n      \n        n\n        ≥\n        k\n        ≥\n        0\n      \n    \n    {\\displaystyle n\\geq k\\geq 0}\n  \n. This formula can be derived from the fact that each k-combination of a set S of n members has \n  \n    \n      \n        k\n        !\n      \n    \n    {\\displaystyle k!}\n  \n permutations so \n  \n    \n      \n        \n          P\n          \n            k\n          \n          \n            n\n          \n        \n        =\n        \n          C\n          \n            k\n          \n          \n            n\n          \n        \n        ×\n        k\n        !\n      \n    \n    {\\displaystyle P_{k}^{n}=C_{k}^{n}\\times k!}\n  \n or \n  \n    \n      \n        \n          C\n          \n            k\n          \n          \n            n\n          \n        \n        =\n        \n          P\n          \n            k\n          \n          \n            n\n          \n        \n        \n          /\n        \n        k\n        !\n      \n    \n    {\\displaystyle C_{k}^{n}=P_{k}^{n}/k!}\n  \n. The set of all k-combinations of a set S is often denoted by \n  \n    \n      \n        \n          \n            \n              \n                (\n              \n              \n                S\n                k\n              \n              \n                )\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle {\\binom {S}{k}}}\n  \n.\nA combination is a selection of n things taken k at a time without repetition. To refer to combinations in which repetition is allowed, the terms k-combination with repetition, k-multiset, or k-selection, are often used. If, in the above example, it were possible to have two of any one kind of fruit there would be 3 more 2-selections: one with two apples, one with two oranges, and one with two pears.\nAlthough the set of three fruits was small enough to write a complete list of combinations, this becomes impractical as the size of the set increases. For example, a poker hand can be described as a 5-combination (k = 5) of cards from a 52 card deck (n = 52). The 5 cards of the hand are all distinct, and the order of cards in the hand does not matter. There are 2,598,960 such combinations, and the chance of drawing any one hand at random is 1 / 2,598,960.",
    "Percentage": "In mathematics, a percentage, percent, or per cent (from Latin  per centum 'by a hundred') is a number or ratio expressed as a fraction of 100. It is often denoted using the percent sign (%), although the abbreviations pct., pct, and sometimes pc are also used. A percentage is a dimensionless number (pure number), primarily used for expressing proportions, but percent is nonetheless a unit of measurement in its orthography and usage.",
    "Permutations": "In mathematics, a permutation of a set can mean one of two different things:\n\nan arrangement of its members in a sequence or linear order, or\nthe act or process of changing the linear order of an ordered set.\nAn example of the first meaning is the six permutations (orderings) of the set {1, 2, 3}: written as tuples, they are (1, 2, 3), (1, 3, 2), (2, 1, 3), (2, 3, 1), (3, 1, 2), and (3, 2, 1). Anagrams of a word whose letters are all different are also permutations: the letters are already ordered in the original word, and the anagram reorders them. The study of permutations of finite sets is an important topic in combinatorics and group theory.\nPermutations are used in almost every branch of mathematics and in many other fields of science. In computer science, they are used for analyzing sorting algorithms; in quantum physics, for describing states of particles; and in biology, for describing RNA sequences.\nThe number of permutations of n distinct objects is n factorial, usually written as n!, which means the product of all positive integers less than or equal to n.\nAccording to the second meaning, a permutation of a set S is defined as a bijection from S to itself. That is, it is a function from S to S for which every element occurs exactly once as an image value. Such a function \n  \n    \n      \n        σ\n        :\n        S\n        →\n        S\n      \n    \n    {\\displaystyle \\sigma :S\\to S}\n  \n is equivalent to the rearrangement of the elements of S in which each element i is replaced by the corresponding \n  \n    \n      \n        σ\n        (\n        i\n        )\n      \n    \n    {\\displaystyle \\sigma (i)}\n  \n. For example, the permutation (3, 1, 2) corresponds to the function \n  \n    \n      \n        σ\n      \n    \n    {\\displaystyle \\sigma }\n  \n defined as\n\n  \n    \n      \n        σ\n        (\n        1\n        )\n        =\n        3\n        ,\n        \n        σ\n        (\n        2\n        )\n        =\n        1\n        ,\n        \n        σ\n        (\n        3\n        )\n        =\n        2.\n      \n    \n    {\\displaystyle \\sigma (1)=3,\\quad \\sigma (2)=1,\\quad \\sigma (3)=2.}\n  \n\nThe collection of all permutations of a set form a group called the symmetric group of the set. The group operation is the composition of functions (performing one rearrangement after the other), which results in another function (rearrangement).\nIn elementary combinatorics, the k-permutations, or partial permutations, are the ordered arrangements of k distinct elements selected from a set. When k is equal to the size of the set, these are the permutations in the previous sense.",
    "Proportion": "Proportionality, proportion or proportional may refer to:",
    "Rounding": "Rounding or rounding off is the process of adjusting a number to an approximate, more convenient value, often with a shorter or simpler representation. For example, replacing $23.4476 with $23.45, the fraction 312/937 with 1/3, or the expression √2 with 1.414.\nRounding is often done to obtain a value that is easier to report and communicate than the original. Rounding can also be important to avoid misleadingly precise reporting of a computed number, measurement, or estimate; for example, a quantity that was computed as 123456 but is known to be accurate only to within a few hundred units is usually better stated as \"about 123500\".\nOn the other hand, rounding of exact numbers will introduce some round-off error in the reported result. Rounding is almost unavoidable when reporting many computations – especially when dividing two numbers in integer or fixed-point arithmetic; when computing mathematical functions such as square roots, logarithms, and sines; or when using a floating-point representation with a fixed number of significant digits. In a sequence of calculations, these rounding errors generally accumulate, and in certain ill-conditioned cases they may make the result meaningless.\nAccurate rounding of transcendental mathematical functions is difficult because the number of extra digits that need to be calculated to resolve whether to round up or down cannot be known in advance. This problem is known as \"the table-maker's dilemma\".\nRounding has many similarities to the quantization that occurs when physical quantities must be encoded by numbers or digital signals.\nA wavy equals sign (≈, approximately equal to) is sometimes used to indicate rounding of exact numbers, e.g. 9.98 ≈ 10. This sign was introduced by Alfred George Greenhill in 1892.\nIdeal characteristics of rounding methods include:\n\nRounding should be done by a function. This way, when the same input is rounded in different instances, the output is unchanged.\nCalculations done with rounding should be close to those done without rounding.\nAs a result of (1) and (2), the output from rounding should be close to its input, often as close as possible by some metric.\nTo be considered rounding, the range will be a subset of the domain, often discrete. A classical range is the integers, Z.\nRounding should preserve symmetries that already exist between the domain and range. With finite precision (or a discrete domain), this translates to removing bias.\nA rounding method should have utility in computer science or human arithmetic where finite precision is used, and speed is a consideration.\nBecause it is not usually possible for a method to satisfy all ideal characteristics, many different rounding methods exist.\nAs a general rule, rounding is idempotent; i.e., once a number has been rounded, rounding it again to the same precision will not change its value. Rounding functions are also monotonic; i.e., rounding two numbers to the same absolute precision will not exchange their order (but may give the same value). In the general case of a discrete range, they are piecewise constant functions.",
    "Scientific notation": "Scientific notation is a way of expressing numbers that are too large or too small to be conveniently written in decimal form, since to do so would require writing out an inconveniently long string of digits. It may be referred to as scientific form or standard index form, or standard form in the United Kingdom. This base ten notation is commonly used by scientists, mathematicians, and engineers, in part because it can simplify certain arithmetic operations. On scientific calculators, it is usually known as \"SCI\" display mode.\n\nIn scientific notation, nonzero numbers are written in the form \n\nor m times ten raised to the power of n, where n is an integer, and the coefficient m is a nonzero real number (usually between 1 and 10 in absolute value, and nearly always written as a terminating decimal). The integer n is called the exponent and the real number m is called the significand or mantissa. The term \"mantissa\" can be ambiguous where logarithms are involved, because it is also the traditional name of the fractional part of the common logarithm.  If the number is negative then a minus sign precedes m, as in ordinary decimal notation. In normalized notation, the exponent is chosen so that the absolute value (modulus) of the significand m is at least 1 but less than 10.\nDecimal floating point is a computer arithmetic system closely related to scientific notation.",
    "Linear motion": "Linear motion, also called rectilinear motion, is one-dimensional motion along a straight line, and can therefore be described mathematically using only one spatial dimension. The linear motion can be of two types: uniform linear motion, with constant velocity (zero acceleration); and non-uniform linear motion, with variable velocity (non-zero acceleration). The motion of a particle (a point-like object) along a line can be described by its position \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n, which varies with \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n (time). An example of linear motion is an athlete running a 100-meter dash along a straight track.\nLinear motion is the most basic of all motion. According to Newton's first law of motion, objects that do not experience any net force will continue to move in a straight line with a constant velocity until they are subjected to a net force. Under everyday circumstances, external forces such as gravity and friction can cause an object to change the direction of its motion, so that its motion cannot be described as linear.\nOne may compare linear motion to general motion. In general motion, a particle's position and velocity are described by vectors, which have a magnitude and direction. In linear motion, the directions of all the vectors describing the system are equal and constant which means the objects move along the same axis and do not change direction. The analysis of such systems may therefore be simplified by neglecting the direction components of the vectors involved and dealing only with the magnitude.",
    "Displacement": "Displacement may refer to:",
    "Speed": "In kinematics, the speed (commonly referred to as v) of an object is the magnitude of the change of its position over time or the magnitude of the change of its position per unit of time; it is thus a non-negative scalar quantity. The average speed of an object in an interval of time is the distance travelled by the object divided by the duration of the interval; the instantaneous speed is the limit of the average speed as the duration of the time interval approaches zero. Speed is the magnitude of velocity (a vector), which indicates additionally the direction of motion.\nSpeed has the dimensions of distance divided by time. The SI unit of speed is the metre per second (m/s), but the most common unit of speed in everyday usage is the kilometre per hour (km/h) or, in the US and the UK, miles per hour (mph). For air and marine travel, the knot is commonly used.\nThe fastest possible speed at which energy or information can travel, according to special relativity, is the speed of light in vacuum c = 299792458 metres per second (approximately 1079000000 km/h or 671000000 mph). Matter cannot quite reach the speed of light, as this would require an infinite amount of energy. In relativity physics, the concept of rapidity replaces the classical idea of speed.",
    "Velocity": "Velocity is a measurement of speed in a certain direction of motion. It is a fundamental concept in kinematics, the branch of classical mechanics that describes the motion of physical objects. Velocity is a vector quantity, meaning that both magnitude and direction are needed to define it (velocity vector). The scalar absolute value (magnitude) of velocity is called speed, a quantity that is measured in metres per second (m/s or m⋅s−1) in the SI (metric) system. For example, \"5 metres per second\" is a scalar, whereas \"5 metres per second east\" is a vector. If there is a change in speed, direction or both, then the object is said to be undergoing an acceleration.",
    "Acceleration": "In mechanics, acceleration is the rate of change of the velocity of an object with respect to time. Acceleration is one of several components of kinematics, the study of motion. Accelerations are vector quantities (in that they have magnitude and direction). The orientation of an object's acceleration is given by the orientation of the net force acting on that object. The magnitude of an object's acceleration, as described by Newton's second law, is the combined effect of two causes:\n\nthe net balance of all external forces acting onto that object — magnitude is directly proportional to this net resulting force;\nthat object's mass, depending on the materials out of which it is made — magnitude is inversely proportional to the object's mass.\nThe SI unit for acceleration is metre per second squared (m⋅s−2, \n  \n    \n      \n        \n          \n            \n              m\n              \n                s\n                \n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\mathrm {\\tfrac {m}{s^{2}}} }\n  \n).\nFor example, when a vehicle starts from a standstill (zero velocity, in an inertial frame of reference) and travels in a straight line at increasing speeds, it is accelerating in the direction of travel. If the vehicle turns, an acceleration occurs toward the new direction and changes its motion vector. The acceleration of the vehicle in its current direction of motion is called a linear acceleration (or tangential acceleration during circular motions), the reaction to which the passengers on board experience as a force pushing them back into their seats. When changing direction, the effecting acceleration is called radial or normal acceleration (or centripetal acceleration during circular motions), the reaction to which the passengers experience as a centrifugal force. If the speed of the vehicle decreases, this is an acceleration in the opposite direction of the velocity vector, sometimes called deceleration or retardation, and passengers experience the reaction to deceleration as an inertial force pushing them forward. Such deceleration is often achieved by retrorocket burning in spacecraft. Both acceleration and deceleration are treated the same, as they are both changes in velocity. Each of these accelerations (tangential, radial, deceleration) is felt by passengers until their relative (differential) velocity is neutralised in reference to the acceleration due to change in speed.",
    "Center of mass": "In physics, the center of mass of a distribution of mass in space (sometimes referred to as the barycenter or balance point) is the unique point at any given time where the weighted relative position of the distributed mass sums to zero. For a rigid body containing its center of mass, this is the point to which a force may be applied to cause a linear acceleration without an angular acceleration. Calculations in mechanics are often simplified when formulated with respect to the center of mass. It is a hypothetical point where the entire mass of an object may be assumed to be concentrated to visualise its motion. In other words, the center of mass is the particle equivalent of a given object for application of Newton's laws of motion.\nIn the case of a single rigid body, the center of mass is fixed in relation to the body, and if the body has uniform density, it will be located at the centroid.  The center of mass may be located outside the physical body, as is sometimes the case for hollow or open-shaped objects, such as a horseshoe. In the case of a distribution of separate bodies, such as the planets of the Solar System, the center of mass may not correspond to the position of any individual member of the system.\nThe center of mass is a useful reference point for calculations in mechanics that involve masses distributed in space, such as the linear and angular momentum of planetary bodies and rigid body dynamics. In orbital mechanics, the equations of motion of planets are formulated as point masses located at the centers of mass (see Barycenter (astronomy) for details). The center of mass frame is an inertial frame in which the center of mass of a system is at rest with respect to the origin of the coordinate system.",
    "Mass": "Mass is an intrinsic property of a body. It was traditionally believed to be related to the quantity of matter in a body, until the discovery of the atom and particle physics. It was found that different atoms and different elementary particles, theoretically with the same amount of matter, have nonetheless different masses. Mass in modern physics has multiple definitions which are conceptually distinct, but physically equivalent. Mass can be experimentally defined as a measure of the body's inertia, meaning the resistance to acceleration (change of velocity) when a net force is applied. The object's mass also determines the strength of its gravitational attraction to other bodies.\nThe SI base unit of mass is the kilogram (kg). In physics, mass is not the same as weight, even though mass is often determined by measuring the object's weight using a spring scale, rather than balance scale comparing it directly with known masses. An object on the Moon would weigh less than it does on Earth because of the lower gravity, but it would still have the same mass. This is because weight is a force, while mass is the property that (along with gravity) determines the strength of this force.\nIn the Standard Model of physics, the mass of elementary particles is believed to be a result of their coupling with the Higgs boson in what is known as the Brout–Englert–Higgs mechanism.",
    "Momentum": "In Newtonian mechanics, momentum (pl.: momenta or momentums; more specifically linear momentum or translational momentum) is the product of the mass and velocity of an object. It is a vector quantity, possessing a magnitude and a direction. If m is an object's mass and v is its velocity (also a vector quantity), then the object's momentum p (from Latin pellere \"push, drive\") is: \n  \n    \n      \n        \n          p\n        \n        =\n        m\n        \n          v\n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {p} =m\\mathbf {v} .}\n  \n\nIn the International System of Units (SI), the unit of measurement of momentum is the kilogram metre per second (kg⋅m/s), which is dimensionally equivalent to the newton-second.\nNewton's second law of motion states that the rate of change of a body's momentum is equal to the net force acting on it. Momentum depends on the frame of reference, but in any inertial frame of reference, it is a conserved quantity, meaning that if a closed system is not affected by external forces, its total momentum does not change. Momentum is also conserved in special relativity (with a modified formula) and, in a modified form, in electrodynamics, quantum mechanics, quantum field theory, and general relativity. It is an expression of one of the fundamental symmetries of space and time: translational symmetry.\nAdvanced formulations of classical mechanics, Lagrangian and Hamiltonian mechanics, allow one to choose coordinate systems that incorporate symmetries and constraints. In these systems the conserved quantity is  generalized momentum, and in general this is different from the kinetic momentum defined above. The concept of generalized momentum is carried over into quantum mechanics, where it becomes an operator on a wave function. The momentum and position operators are related by the Heisenberg uncertainty principle.\nIn continuous systems such as electromagnetic fields, fluid dynamics and deformable bodies, a momentum density can be defined as momentum per volume (a volume-specific quantity). A continuum version of the conservation of momentum leads to equations such as the Navier–Stokes equations for fluids or the Cauchy momentum equation for deformable solids or fluids.",
    "Newton's laws of motion": "Newton's laws of motion are three physical laws that describe the relationship between the motion of an object and the forces acting on it. These laws, which provide the basis for Newtonian mechanics, can be paraphrased as follows:\n\nA body remains at rest, or in motion at a constant speed in a straight line, unless it is acted upon by a force.\nAt any instant of time, the net force on a body is equal to the body's acceleration multiplied by its mass or, equivalently, the rate at which the body's momentum is changing with time.\nIf two bodies exert forces on each other, these forces have the same magnitude but opposite directions.\nThe three laws of motion were first stated by Isaac Newton in his Philosophiæ Naturalis Principia Mathematica (Mathematical Principles of Natural Philosophy), originally published in 1687. Newton used them to investigate and explain the motion of many physical objects and systems. In the time since Newton, new insights, especially around the concept of energy, built the field of classical mechanics on his foundations. In modern times, limitations to Newton's laws have been discovered; new theories were consequently developed, such as quantum mechanics and relativity to address the physics of objects in more extreme cases.",
    "Work (physics)": "In science, work is the energy transferred to or from an object via the application of force along a displacement. In its simplest form, for a constant force aligned with the direction of motion, the work equals the product of the force strength and the distance traveled. A force is said to do positive work if it has a component in the direction of the displacement of the point of application. A force does negative work if it has a component opposite to the direction of the displacement at the point of application of the force.\nFor example, when a ball is held above the ground and then dropped, the work done by the gravitational force on the ball as it falls is positive, and is equal to the weight of the ball (a force) multiplied by the distance to the ground (a displacement). If the ball is thrown upwards, the work done by the gravitational force is negative, and is equal to the weight multiplied by the displacement in the upwards direction.\nBoth force and displacement are vectors. The work done is given by the dot product of the two vectors, where the result is a scalar. When the force F is constant and the angle θ between the force and the displacement s is also constant, then the work done is given by:\n\n  \n    \n      \n        W\n        =\n        \n          F\n        \n        ⋅\n        \n          s\n        \n        =\n        F\n        s\n        cos\n        ⁡\n        \n          θ\n        \n      \n    \n    {\\displaystyle W=\\mathbf {F} \\cdot \\mathbf {s} =Fs\\cos {\\theta }}\n  \n\nIf the force and/or displacement is variable, then work is given by the line integral:\n\n  \n    \n      \n        \n          \n            \n              \n                W\n              \n              \n                \n                =\n                ∫\n                \n                  F\n                \n                ⋅\n                d\n                \n                  s\n                \n              \n            \n            \n              \n              \n                \n                =\n                ∫\n                \n                  F\n                \n                ⋅\n                \n                  \n                    \n                      d\n                      \n                        s\n                      \n                    \n                    \n                      d\n                      t\n                    \n                  \n                \n                d\n                t\n              \n            \n            \n              \n              \n                \n                =\n                ∫\n                \n                  F\n                \n                ⋅\n                \n                  v\n                \n                d\n                t\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}W&=\\int \\mathbf {F} \\cdot d\\mathbf {s} \\\\&=\\int \\mathbf {F} \\cdot {\\frac {d\\mathbf {s} }{dt}}dt\\\\&=\\int \\mathbf {F} \\cdot \\mathbf {v} dt\\end{aligned}}}\n  \n\nwhere \n  \n    \n      \n        d\n        \n          s\n        \n      \n    \n    {\\displaystyle d\\mathbf {s} }\n  \n is the infinitesimal change in displacement vector, \n  \n    \n      \n        d\n        t\n      \n    \n    {\\displaystyle dt}\n  \n is the infinitesimal increment of time, and \n  \n    \n      \n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {v} }\n  \n represents the velocity vector. The first equation represents force as a function of the position and the second and third equations represent force as a function of time.\nWork is a scalar quantity, so it has only magnitude and no direction. Work transfers energy from one place to another, or one form to another. The SI unit of work is the joule (J), the same unit as for energy.",
    "Free body diagram": "In physics and engineering, a free body diagram (FBD; also called a force diagram) is a graphical illustration used to visualize the applied forces, moments, and resulting reactions on a free body in a given condition. It depicts a body or connected bodies with all the applied forces and moments, and reactions, which act on the body(ies). The body may consist of multiple internal members (such as a truss), or be a compact body (such as a beam). A series of free bodies and other diagrams may be necessary to solve complex problems. Sometimes in order to calculate the resultant force graphically the applied forces are arranged as the edges of a polygon of forces or force polygon (see § Polygon of forces).",
    "Energy": "Energy (from Ancient Greek  ἐνέργεια (enérgeia) 'activity') is the quantitative property that is transferred to a body or to a physical system, recognizable in the performance of work and in the form of heat and light. Energy is a conserved quantity—the law of conservation of energy states that energy can be converted in form, but not created or destroyed. The unit of measurement for energy in the International System of Units (SI) is the joule (J).\nForms of energy include the kinetic energy of a moving object, the potential energy stored by an object (for instance due to its position in a field), the elastic energy stored in a solid object, chemical energy associated with chemical reactions, the radiant energy carried by electromagnetic radiation, the internal energy contained within a thermodynamic system, and rest energy associated with an object's rest mass. These are not mutually exclusive.\nAll living organisms constantly take in and release energy. The Earth's climate and ecosystems processes are driven primarily by radiant energy from the Sun.",
    "Conservation of energy": "The law of conservation of energy states that the total energy of an isolated system remains constant; it is said to be conserved over time. In the case of a closed system, the principle says that the total amount of energy within the system can only be changed through energy entering or leaving the system. Energy can neither be created nor destroyed; rather, it can only be transformed or transferred from one form to another. For instance, chemical energy is converted to kinetic energy when a stick of dynamite explodes. If one adds up all forms of energy that were released in the explosion, such as the kinetic energy and potential energy of the pieces, as well as heat and sound, one will get the exact decrease of chemical energy in the combustion of the dynamite.\nClassically, the conservation of energy was distinct from the conservation of mass. However, special relativity shows that mass is related to energy and vice versa by \n  \n    \n      \n        E\n        =\n        m\n        \n          c\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E=mc^{2}}\n  \n, the equation representing mass–energy equivalence, and science now takes the view that mass-energy as a whole is conserved. This implies that  mass can be converted to energy, and vice versa. This is observed in the nuclear binding energy of atomic nuclei, where a mass defect is measured. It is believed that mass-energy equivalence becomes important in extreme physical conditions, such as those that likely existed in the universe very shortly after the Big Bang or when black holes emit Hawking radiation.\nGiven the stationary-action principle, the conservation of energy can be rigorously proven by Noether's theorem as a consequence of continuous time translation symmetry; that is, from the fact that the laws of physics do not change over time.\nA consequence of the law of conservation of energy is that a perpetual motion machine of the first kind cannot exist; that is to say, no system without an external energy supply can deliver an unlimited amount of energy to its surroundings. Depending on the definition of energy, the conservation of energy can arguably be violated by general relativity on the cosmological scale. In quantum mechanics, Noether's theorem is known to apply to the expected value, making any consistent conservation violation provably impossible, but whether individual conservation-violating events could ever exist or be observed is subject to some debate.",
    "Elastic collision": "In physics, an elastic collision occurs between two physical objects in which the total kinetic energy of the two bodies remains the same. In an ideal, perfectly elastic collision, there is no net conversion of kinetic energy into other forms such as heat, sound, or potential energy.\nDuring the collision of small objects, kinetic energy is first converted to potential energy associated with a repulsive or attractive force between the particles (when the particles move against this force, i.e. the angle between the force and the relative velocity is obtuse), then this potential energy is converted back to kinetic energy (when the particles move with this force, i.e. the angle between the force and the relative velocity is acute).\nCollisions of atoms are elastic, for example Rutherford backscattering.\nA useful special case of elastic collision is when the two bodies have equal mass, in which case they will simply exchange their momenta.\nThe molecules—as distinct from atoms—of a gas or liquid rarely experience perfectly elastic collisions because kinetic energy is exchanged between the molecules’ translational motion and their internal degrees of freedom with each collision. At any instant, half the collisions are, to a varying extent, inelastic collisions (the pair possesses less kinetic energy in their translational motions after the collision than before), and the other half could be described as \"super-elastic\" (possessing more kinetic energy after the collision than before). Averaged across the entire sample, molecular collisions can be regarded as essentially elastic as long as black-body radiation is negligible or doesn't escape.\nIn the case of macroscopic bodies, perfectly elastic collisions are an ideal never fully realized, but approximated by the interactions of objects such as billiard balls.\nWhen considering energies, possible rotational energy before or after a collision may also play a role.",
    "Inelastic collision": "An inelastic collision, in contrast to an elastic collision, is a collision in which kinetic energy is not conserved due to the action of internal friction.\nIn collisions of macroscopic bodies, some kinetic energy is turned into vibrational energy of the atoms, causing a heating effect, and the bodies are deformed.\nThe molecules of a gas or liquid rarely experience perfectly elastic collisions because kinetic energy is exchanged between the molecules' translational motion and their internal degrees of freedom with each collision. At any one instant, half the collisions are – to a varying extent – inelastic (the pair possesses less kinetic energy after the collision than before), and half could be described as “super-elastic” (possessing more kinetic energy after the collision than before). Averaged across an entire sample, molecular collisions are elastic. \nAlthough inelastic collisions do not conserve kinetic energy, they do obey conservation of momentum. Simple ballistic pendulum problems obey the conservation of kinetic energy only when the block swings to its largest angle.\nIn nuclear physics, an inelastic collision is one in which the incoming particle causes the nucleus it strikes to become excited or to break up. Deep inelastic scattering is a method of probing the structure of subatomic particles in much the same way as Rutherford probed the inside of the atom (see Rutherford scattering). Such experiments were performed on protons in the late 1960s using high-energy electrons at the Stanford Linear Accelerator (SLAC). As in Rutherford scattering, deep inelastic scattering of electrons by proton targets revealed that most of the incident electrons interact very little and pass straight through, with only a small number bouncing back. This indicates that the charge in the proton is concentrated in small lumps, reminiscent of Rutherford's discovery that the positive charge in an atom is concentrated at the nucleus. However, in the case of the proton, the evidence suggested three distinct concentrations of charge (quarks) and not one.",
    "Inertia": "Inertia is the natural tendency of objects in motion to stay in motion and objects at rest to stay at rest, unless a force causes its velocity to change. It is one of the fundamental principles in classical physics, and described by Isaac Newton in his first law of motion (also known as The Principle of Inertia). It is one of the primary manifestations of mass, one of the core quantitative properties of physical systems. Newton writes:\n\nLAW I. Every object perseveres in its state of rest, or of uniform motion in a right line, except insofar as it is compelled to change that state by forces impressed thereon.\nIn his 1687 work Philosophiæ Naturalis Principia Mathematica, Newton defined inertia as a property:\n\nDEFINITION III. The vis insita, or innate force of matter, is a power of resisting by which every body, as much as in it lies, endeavours to persevere in its present state, whether it be of rest or of moving uniformly forward in a right line.",
    "Moment of inertia": "The moment of inertia, otherwise known as the mass moment of inertia, angular/rotational mass, second moment of mass, or most accurately, rotational inertia, of a rigid body is defined relatively to a rotational axis. It is the ratio between the torque applied and the resulting angular acceleration about that axis. It plays the same role in rotational motion as mass does in linear motion. A body's moment of inertia about a particular axis depends both on the mass and its distribution relative to the axis, increasing with mass and distance from the axis.\nIt is an extensive (additive) property: for a point mass the moment of inertia is simply the mass times the square of the perpendicular distance to the axis of rotation. The moment of inertia of a rigid composite system is the sum of the moments of inertia of its component subsystems (all taken about the same axis). Its simplest definition is the second moment of mass with respect to distance from an axis.\nFor bodies forced to rotate in a plane, only their moment of inertia about an axis perpendicular to the plane, a scalar value, matters. For bodies free to rotate in all three dimensions, their moments can be described by a symmetric 3-by-3 matrix, with a set of mutually perpendicular principal axes for which this matrix is diagonal and torques around the axes act independently of each other.",
    "Kinetic energy": "In physics, the kinetic energy of an object is the form of energy that it possesses due to its motion.\nIn classical mechanics, the kinetic energy of a non-rotating object of mass m traveling at a speed v is \n  \n    \n      \n        \n          \n            1\n            2\n          \n        \n        m\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\textstyle {\\frac {1}{2}}mv^{2}}\n  \n. \nThe kinetic energy of an object is equal to the work, or force (F) in the direction of motion times its displacement (s), needed to accelerate the object from rest to its given speed. The same amount of work is done by the object when decelerating from its current speed to a state of rest.\nThe SI unit of energy is the joule, while the English unit of energy is the foot-pound.\nIn relativistic mechanics, \n  \n    \n      \n        \n          \n            1\n            2\n          \n        \n        m\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\textstyle {\\frac {1}{2}}mv^{2}}\n  \n is a good approximation of kinetic energy only when v is much less than the speed of light.",
    "Potential energy": "In physics, potential energy is the energy of an object or system due to the body's position relative to other objects, or the configuration of its particles. The energy is equal to the work done against any restoring forces, such as gravity or those in a spring.\nThe term potential energy was introduced by the 19th-century Scottish engineer and physicist William Rankine, although it has links to the ancient Greek philosopher Aristotle's concept of potentiality.\nCommon types of potential energy include gravitational potential energy, the elastic potential energy of a deformed spring, and the electric potential energy of an electric charge and an electric field. The unit for energy in the International System of Units (SI) is the joule (symbol J).\nPotential energy is associated with forces that act on a body in a way that the total work done by these forces on the body depends only on the initial and final positions of the body in space. These forces, whose total work is path independent, are called conservative forces. If the force acting on a body varies over space, then one has a force field; such a field is described by vectors at every point in space, which is, in turn, called a vector field. A conservative vector field can be simply expressed as the gradient of a certain scalar function, called a scalar potential. The potential energy is related to, and can be obtained from, this potential function.",
    "Rotational energy": "Rotational energy or angular kinetic energy is kinetic energy due to the rotation of an object and is part of its total kinetic energy. Looking at rotational energy separately around an object's axis of rotation, the following dependence on the object's moment of inertia is observed:\n\n  \n    \n      \n        \n          E\n          \n            rotational\n          \n        \n        =\n        \n          \n            \n              1\n              2\n            \n          \n        \n        I\n        \n          ω\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{\\text{rotational}}={\\tfrac {1}{2}}I\\omega ^{2}}\n  \n\nwhere\n\nThe mechanical work required for or applied during rotation is the torque times the rotation angle. The instantaneous power of an angularly accelerating body is the torque times the angular velocity. For free-floating (unattached) objects, the axis of rotation is commonly around its center of mass.\nNote the close relationship between the result for rotational energy and the energy held by linear (or translational) motion:\n\n  \n    \n      \n        \n          E\n          \n            translational\n          \n        \n        =\n        \n          \n            \n              1\n              2\n            \n          \n        \n        m\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{\\text{translational}}={\\tfrac {1}{2}}mv^{2}}\n  \n\nIn the rotating system, the moment of inertia, I, takes the role of the mass, m, and the angular velocity, \n  \n    \n      \n        ω\n      \n    \n    {\\displaystyle \\omega }\n  \n, takes the role of the linear velocity, v. The rotational energy of a rolling cylinder varies from one half of the translational energy (if it is massive) to the same as the translational energy (if it is hollow).\nAn example is the calculation of the rotational kinetic energy of the Earth. As the Earth has a sidereal rotation period of 23.93 hours, it has an angular velocity of 7.29×10−5 rad·s−1. The Earth has a moment of inertia, I = 8.04×1037 kg·m2. Therefore, it has a rotational kinetic energy of 2.14×1029 J.\nPart of the Earth's rotational energy can also be tapped using tidal power. Additional friction of the two global tidal waves creates energy in a physical manner, infinitesimally slowing down Earth's angular velocity ω. Due to the conservation of angular momentum, this process transfers angular momentum to the Moon's orbital motion, increasing its distance from Earth and its orbital period (see tidal locking for a more detailed explanation of this process).",
    "Entropy": "Entropy is a scientific concept, most commonly associated with states of disorder, randomness, or uncertainty. The term and the concept are used in diverse fields, from classical thermodynamics, where it was first recognized, to the microscopic description of nature in statistical physics, and to the principles of information theory. It has found far-ranging applications in chemistry and physics, in biological systems and their relation to life, in cosmology, economics, and information systems including the transmission of information in telecommunication.\nEntropy is central to the second law of thermodynamics, which states that the entropy of an isolated system left to spontaneous evolution cannot decrease with time. As a result, isolated systems evolve toward thermodynamic equilibrium, where the entropy is highest. \"High\" entropy means that energy is more disordered or dispersed, while \"low\" entropy means that energy is more ordered or concentrated. A consequence of the second law of thermodynamics is that certain processes are irreversible.\nThe thermodynamic concept was referred to by Scottish scientist and engineer William Rankine in 1850 with the names thermodynamic function and heat-potential. In 1865, German physicist Rudolf Clausius, one of the leading founders of the field of thermodynamics, defined it as the quotient of an infinitesimal amount of heat to the instantaneous temperature. He initially described it as transformation-content, in German Verwandlungsinhalt, and later coined the term entropy from a Greek word for transformation.\nAustrian physicist Ludwig Boltzmann explained entropy as the measure of the number of possible microscopic arrangements or states of individual atoms and molecules of a system that comply with the macroscopic condition of the system. He thereby introduced the concept of statistical disorder and probability distributions into a new field of thermodynamics, called statistical mechanics, and found the link between the microscopic interactions, which fluctuate about an average configuration, to the macroscopically observable behaviour, in form of a simple logarithmic law, with a proportionality constant, the Boltzmann constant, which has become one of the defining universal constants for the modern International System of Units.",
    "First law of thermodynamics": "The first law of thermodynamics is a formulation of the law of conservation of energy in the context of thermodynamic processes. For a thermodynamic process affecting a thermodynamic system without transfer of matter, the law distinguishes two principal forms of energy transfer, heat and thermodynamic work. The law also defines the internal energy of a system, an extensive property for taking account of the balance of heat transfer, thermodynamic work, and matter transfer, into and out of the system. Energy cannot be created or destroyed, but it can be transformed from one form to another. In an externally isolated system, with internal changes, the sum of all forms of energy is constant.\nAn equivalent statement is that perpetual motion machines of the first kind are impossible; work done by a system on its surroundings requires that the system's internal energy be consumed, so that the amount of internal energy lost by that work must be resupplied as heat by an external energy source or as work by an external machine acting on the system to sustain the work of the system continuously.",
    "Heat": "In thermodynamics, heat is energy in transfer between a thermodynamic system and its surroundings by such mechanisms as thermal conduction, electromagnetic radiation, and friction, which are microscopic in nature, involving sub-atomic, atomic, or molecular particles, or small surface irregularities, as distinct from the macroscopic modes of energy transfer, which are thermodynamic work and transfer of matter. For a closed system (transfer of matter excluded), the heat involved in a process is the difference in internal energy between the final and initial states of a system, after subtracting the work done in the process. For a closed system, this is the formulation of the first law of thermodynamics.\nCalorimetry is measurement of quantity of energy transferred as heat by its effect on the states of interacting bodies, for example, by the amount of ice melted or by change in temperature of a body.\nIn the International System of Units (SI), the unit of measurement for heat, as a form of energy, is the joule (J).\nWith various other meanings, the word 'heat' is also used in engineering, and it occurs also in ordinary language, but such are not the topic of the present article.",
    "Heat transfer": "Heat transfer is a discipline of thermal engineering that concerns the generation, use, conversion, and exchange of thermal energy (heat) between physical systems. Heat transfer is classified into various mechanisms, such as thermal conduction, thermal convection, thermal radiation, and transfer of energy by phase changes. Engineers also consider the transfer of mass of differing chemical species (mass transfer in the form of advection), either cold or hot, to achieve heat transfer. While these mechanisms have distinct characteristics, they often occur simultaneously in the same system.\nHeat conduction, also called diffusion, is the direct microscopic exchanges of kinetic energy of particles (such as molecules) or quasiparticles (such as lattice waves) through the boundary between two systems. When an object is at a different temperature from another body or its surroundings, heat flows so that the body and the surroundings reach the same temperature, at which point they are in thermal equilibrium. Such spontaneous heat transfer always occurs from a region of high temperature to another region of lower temperature, as described in the second law of thermodynamics.\nHeat convection occurs when the bulk flow of a fluid (gas or liquid) carries its heat through the fluid. All convective processes also move heat partly by diffusion, as well. The flow of fluid may be forced by external processes, or sometimes (in gravitational fields) by buoyancy forces caused when thermal energy expands the fluid (for example in a fire plume), thus influencing its own transfer. The latter process is often called \"natural convection\". The former process is often called \"forced convection.\" In this case, the fluid is forced to flow by use of a pump, fan, or other mechanical means.\nThermal radiation occurs through a vacuum or any transparent medium (solid or fluid or gas). It is the transfer of energy by means of photons or electromagnetic waves governed by the same laws.",
    "Second law of thermodynamics": "The second law of thermodynamics is a physical law based on universal empirical observation concerning heat and energy interconversions. A simple statement of the law is that heat always flows spontaneously from hotter to colder regions of matter (or 'downhill' in terms of the temperature gradient). Another statement is: \"Not all heat can be converted into work in a cyclic process.\" These are informal definitions, however; more formal definitions appear below.\nThe second law of thermodynamics establishes the concept of entropy as a physical property of a thermodynamic system. It predicts whether processes are forbidden despite obeying the requirement of conservation of energy as expressed in the first law of thermodynamics and provides necessary criteria for spontaneous processes. For example, the first law allows the process of a cup falling off a table and breaking on the floor, as well as allowing the reverse process of the cup fragments coming back together and 'jumping' back onto the table, while the second law allows the former and denies the latter. The second law may be formulated by the observation that the entropy of isolated systems left to spontaneous evolution cannot decrease, as they always tend toward a state of thermodynamic equilibrium where the entropy is highest at the given internal energy. An increase in the combined entropy of system and surroundings accounts for the irreversibility of natural processes, often referred to in the concept of the arrow of time.\nHistorically, the second law was an empirical finding that was accepted as an axiom of thermodynamic theory. Statistical mechanics provides a microscopic explanation of the law in terms of probability distributions of the states of large assemblies of atoms or molecules. The second law has been expressed in many ways. Its first formulation, which preceded the proper definition of entropy and was based on caloric theory, is Carnot's theorem, formulated by the French scientist Sadi Carnot, who in 1824 showed that the efficiency of conversion of heat to work in a heat engine has an upper limit. The first rigorous definition of the second law based on the concept of entropy came from German scientist Rudolf Clausius in the 1850s and included his statement that heat can never pass from a colder to a warmer body without some other change, connected therewith, occurring at the same time.\nThe second law of thermodynamics allows the definition of the concept of thermodynamic temperature, but this has been formally delegated to the zeroth law of thermodynamics.",
    "Temperature": "Temperature quantitatively expresses the attribute of hotness or coldness. Temperature is measured with a thermometer. It reflects the average kinetic energy of the vibrating and colliding atoms making up a substance.\nThermometers are calibrated in various temperature scales that historically have relied on various reference points and thermometric substances for definition. The most common scales are the Celsius scale with the unit symbol °C (formerly called centigrade), the Fahrenheit scale (°F), and the Kelvin scale (K), with the third being used predominantly for scientific purposes. The kelvin is one of the seven base units in the International System of Units (SI).\nAbsolute zero, i.e., zero kelvin, 0 K = −273.15 °C, is the lowest point in the thermodynamic temperature scale. Experimentally, it can be approached very closely but not actually reached, as recognized in the third law of thermodynamics. It would be impossible to extract energy as heat from a body at that temperature.\nTemperature is important in all fields of natural science, including physics, chemistry, Earth science, astronomy, medicine, biology, ecology, material science, metallurgy, mechanical engineering and geography as well as most aspects of daily life.",
    "Thermal energy": "The term \"thermal energy\" is often used ambiguously in physics and engineering. It can denote several different physical concepts, including:\n\nInternal energy: The energy contained within a body of matter or radiation, excluding the potential energy of the whole system.\nHeat: Energy in transfer between a system and its surroundings by mechanisms other than thermodynamic work and transfer of matter.\nThe characteristic energy kBT, where T denotes temperature and kB denotes the Boltzmann constant; it is twice that associated with each degree of freedom.\nMark Zemansky (1970) has argued that the term \"thermal energy\" is best avoided due to its ambiguity. He suggests using more precise terms such as \"internal energy\" and \"heat\" to avoid confusion. The term is, however, used in some textbooks.",
    "Thermodynamic cycle": "A thermodynamic cycle consists of linked sequences of thermodynamic processes that involve transfer of heat and work into and out of the system, while varying pressure, temperature, and other state variables within the system, and that eventually returns the system to its initial state. In the process of passing through a cycle, the working fluid (system) may convert heat from a warm source into useful work, and dispose of the remaining heat to a cold sink, thereby acting as a heat engine. Conversely, the cycle may be reversed and use work to move heat from a cold source and transfer it to a warm sink thereby acting as a heat pump. If at every point in the cycle the system is in thermodynamic equilibrium, the cycle is reversible. Whether carried out reversibly or irreversibly, the net entropy change of the system is zero, as entropy is a state function.\nDuring a closed cycle, the system returns to its original thermodynamic state of temperature and pressure. Process quantities (or path quantities), such as heat and work are process dependent. For a cycle for which the system returns to its initial state the first law of thermodynamics applies:\n\n  \n    \n      \n        Δ\n        U\n        =\n        \n          E\n          \n            i\n            n\n          \n        \n        −\n        \n          E\n          \n            o\n            u\n            t\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\Delta U=E_{in}-E_{out}=0}\n  \n\nThe above states that there is no change of the internal energy (\n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n) of the system over the cycle. \n  \n    \n      \n        \n          E\n          \n            i\n            n\n          \n        \n      \n    \n    {\\displaystyle E_{in}}\n  \n represents the total work and heat input during the cycle and \n  \n    \n      \n        \n          E\n          \n            o\n            u\n            t\n          \n        \n      \n    \n    {\\displaystyle E_{out}}\n  \n would be the total work and heat output during the cycle. The repeating nature of the process path allows for continuous operation, making the cycle an important concept in thermodynamics. Thermodynamic cycles are often represented mathematically as quasistatic processes in the modeling of the workings of an actual device.",
    "Volume (thermodynamics)": "In thermodynamics, the volume of a system is an important extensive parameter for describing its thermodynamic state. The specific volume, an intensive property, is the system's volume per unit mass. Volume is a function of state and is interdependent with other thermodynamic properties such as pressure and temperature. For example, volume is related to the pressure and temperature of an ideal gas by the ideal gas law.\nThe physical region covered by a system may or may not coincide with a control volume used to analyze the system.",
    "Work (thermodynamics)": "Thermodynamic work is one of the principal kinds of process by which a thermodynamic system can interact with and transfer energy to its surroundings. This results in externally measurable macroscopic forces on the system's surroundings, which can cause mechanical work, to lift a weight, for example, or cause changes in electromagnetic, or gravitational variables. Also, the surroundings can perform thermodynamic work on a thermodynamic system, which is measured by an opposite sign convention.\nFor thermodynamic work, appropriately chosen externally measured quantities are exactly matched by values of or contributions to changes in macroscopic internal state variables of the system, which always occur in conjugate pairs, for example pressure and volume or magnetic flux density and magnetization.\nIn the International System of Units (SI), work is measured in joules (symbol J). The rate at which work is performed is power, measured in joules per second, and denoted with the unit watt (W).",
    "Bearing": "Bearing(s) may refer to:\n\nBearing (angle), a term for direction\nBearing (mechanical), a component that separates moving parts and takes a load\nBridge bearing, a component separating a bridge pier and deck\nBearing BTS Station in Bangkok\nBearings (album), by Ronnie Montrose in 2000",
    "Angle": "In geometry, an angle is formed by two lines that meet at a point. Each line is called a side of the angle, and the point they share is called the vertex of the angle. The term angle is used to denote both geometric figures and their size or magnitude. Angular measure or measure of angle are sometimes used to distinguish between the measurement and figure itself. The measurement of angles is intrinsically linked with circles and rotation, and this is often visualized or defined using the arc of a circle centered at the vertex and lying between the sides.",
    "Degree": "Degree may refer to:",
    "Minute": "A minute is a unit of time defined as equal to 60 seconds.\nIt is not a unit in the International System of Units (SI), but is accepted for use with SI. The SI symbol for minutes is min (without a dot). The prime symbol ′ is also sometimes used informally to denote minutes.\nIn the UTC time standard, a minute on rare occasions has 61 seconds, a consequence of leap seconds; there is also a provision to insert a negative leap second, which would result in a 59-second minute, but this has never happened in more than 40 years under this system.",
    "Radian": "The radian, denoted by the symbol rad, is the unit of angle in the International System of Units (SI) and is the standard unit of angular measure used in many areas of mathematics. It is defined such that one radian is the angle subtended at the center of a plane circle by an arc that is equal in length to the radius. The unit is defined in the SI as the coherent unit for plane angle, as well as for phase angle. Angles without explicitly specified units are generally assumed to be measured in radians, especially in mathematical writing.",
    "Circumference": "In geometry, the circumference (from Latin  circumferēns 'carrying around, circling') is the perimeter of a circle or ellipse. The circumference is the arc length of the circle, as if it were opened up and straightened out to a line segment. More generally, the perimeter is the curve length around any closed figure. \nCircumference may also refer to the circle itself, that is, the locus corresponding to the edge of a disk. \nThe circumference of a sphere is the circumference, or length, of any one of its great circles.",
    "Diameter": "In geometry, a diameter of a circle is any straight line segment that passes through the centre of the circle and whose endpoints lie on the circle. It can also be defined as the longest chord of the circle. Both definitions are also valid for the diameter of a sphere.\nIn more modern usage, the length \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n  \n of a diameter is also called the diameter. In this sense one speaks of the diameter rather than a diameter (which refers to the line segment itself), because all diameters of a circle or sphere have the same length, this being twice the radius \n  \n    \n      \n        r\n        .\n      \n    \n    {\\displaystyle r.}\n  \n\n  \n    \n      \n        d\n        =\n        2\n        r\n        \n        \n          or equivalently\n        \n        \n        r\n        =\n        \n          \n            d\n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle d=2r\\qquad {\\text{or equivalently}}\\qquad r={\\frac {d}{2}}.}\n  \n\nThe word \"diameter\" is derived from Ancient Greek: διάμετρος (diametros), \"diameter of a circle\", from διά (dia), \"across, through\" and μέτρον (metron), \"measure\". It is often abbreviated \n  \n    \n      \n        \n          DIA\n        \n        ,\n        \n          dia\n        \n        ,\n        d\n        ,\n      \n    \n    {\\displaystyle {\\text{DIA}},{\\text{dia}},d,}\n  \n or \n  \n    \n      \n        ∅\n        .\n      \n    \n    {\\displaystyle \\varnothing .}",
    "Amplitude": "The amplitude of a periodic variable is a measure of its change in a single period (such as time or spatial period). The amplitude of a non-periodic signal is its magnitude compared with a reference value. There are various definitions of amplitude (see below), which are all functions of the magnitude of the differences between the variable's extreme values. In older texts, the phase of a periodic function is sometimes called the amplitude.",
    "Dot product": "In mathematics, the dot product or scalar product is an algebraic operation that takes two equal-length sequences of numbers (usually coordinate vectors), and returns a single number. In Euclidean geometry, the dot product of the Cartesian coordinates of two vectors is widely used. It is often called the inner product (or rarely the projection product) of Euclidean space, even though it is not the only inner product that can be defined on Euclidean space (see Inner product space for more). It should not be confused with the cross product.\nAlgebraically, the dot product is the sum of the products of the corresponding entries of the two sequences of numbers. Geometrically, it is the product of the Euclidean magnitudes of the two vectors and the cosine of the angle between them. These definitions are equivalent when using Cartesian coordinates. In modern geometry, Euclidean spaces are often defined by using vector spaces. In this case, the dot product is used for defining lengths (the length of a vector is the square root of the dot product of the vector by itself) and angles (the cosine of the angle between two vectors is the quotient of their dot product by the product of their lengths).\nThe name \"dot product\" is derived from the dot operator \" ⋅ \" that is often used to designate this operation; the alternative name \"scalar product\" emphasizes that the result is a scalar, rather than a vector (as with the vector product in three-dimensional space).",
    "Norm (mathematics)": "In mathematics, a norm is a function from a real or complex vector space to the non-negative real numbers that behaves in certain ways like the distance from the origin: it commutes with scaling, obeys a form of the triangle inequality, and zero is only at the origin. In particular, the Euclidean distance in a Euclidean space is defined by a norm on the associated Euclidean vector space, called the Euclidean norm, the 2-norm, or, sometimes, the magnitude or length of the vector. This norm can be defined as the square root of the inner product of a vector with itself.\nA seminorm satisfies the first two properties of a norm but may be zero for vectors other than the origin. A vector space with a specified norm is called a normed vector space. In a similar manner, a vector space with a seminorm is called a seminormed vector space.\nThe term pseudonorm has been used for several related meanings. It may be a synonym of \"seminorm\". It can also refer to a norm that can take infinite values or to certain functions parametrised by a directed set.",
    "Position vector": "In geometry, a position or position vector, also known as location vector or radius vector, is a Euclidean vector that represents a point P in space. Its length represents the distance in relation to an arbitrary reference origin O, and its direction represents the angular orientation with respect to given reference axes. Usually denoted x, r, or s, it corresponds to the straight line segment from O to P.\nIn other words, it is the displacement or translation that maps the origin to P:\n\n  \n    \n      \n        \n          r\n        \n        =\n        \n          \n            \n              O\n              P\n            \n            →\n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {r} ={\\overrightarrow {OP}}.}\n  \n\nThe term position vector is used mostly in the fields of differential geometry, mechanics and occasionally vector calculus.\nFrequently this is used in two-dimensional or three-dimensional space, but can be easily generalized to Euclidean spaces and affine spaces of any dimension.",
    "Scalar multiplication": "In mathematics, scalar multiplication is one of the basic operations defining a vector space in linear algebra (or more generally, a module in abstract algebra). In common geometrical contexts, scalar multiplication of a real Euclidean vector by a positive real number multiplies the magnitude of the vector without changing its direction. Scalar multiplication is the multiplication of a vector by a scalar (where the product is a vector), and is to be distinguished from inner product of two vectors (where the product is a scalar).",
    "Vector addition": "In mathematics, physics, and engineering, a Euclidean vector or simply a vector (sometimes called a geometric vector or spatial vector) is a geometric object that has magnitude (or length) and direction. Euclidean vectors can be added and scaled to form a vector space. A vector quantity is a vector-valued physical quantity, including units of measurement and possibly a support, formulated as a directed line segment. A vector is frequently depicted graphically as an arrow connecting an initial point A with a terminal point B, and denoted by \n  \n    \n      \n        \n          \n            \n              \n                A\n                B\n              \n              \n                ⟶\n              \n            \n          \n        \n        .\n      \n    \n    {\\textstyle {\\stackrel {\\longrightarrow }{AB}}.}\n  \n\nA vector is what is needed to \"carry\" the point A to the point B; the Latin word vector means 'carrier'. It was first used by 18th century astronomers investigating planetary revolution around the Sun. The magnitude of the vector is the distance between the two points, and the direction refers to the direction of displacement from A to B. Many algebraic operations on real numbers such as addition, subtraction, multiplication, and negation have close analogues for vectors, operations which obey the familiar algebraic laws of commutativity, associativity, and distributivity. These operations and associated laws qualify Euclidean vectors as an example of the more generalized concept of vectors defined simply as elements of a vector space.\nVectors play an important role in physics: the velocity and acceleration of a moving object and the forces acting on it can all be described with vectors. Many other physical quantities can be usefully thought of as vectors. Although most of them do not represent distances (except, for example, position or displacement), their magnitude and direction can still be represented by the length and direction of an arrow. The mathematical representation of a physical vector depends on the coordinate system used to describe it. Other vector-like objects that describe physical quantities and transform in a similar way under changes of the coordinate system include pseudovectors and tensors.",
    "Zero vector": "In mathematics, a zero element is one of several generalizations of the number zero to other algebraic structures. These alternate meanings may or may not reduce to the same thing, depending on the context."
}